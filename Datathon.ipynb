{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Datathon.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFZ7RBNyuah5x14EzwgLDL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexisStdp/AlexisStdp.github.io/blob/master/Datathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oZRrPasNlas",
        "outputId": "f3e0468c-350f-4bcf-9151-db2a53117391"
      },
      "source": [
        "!git clone https://AlexisStdp:g1thUBpwdNn@github.com/ixil/datathon21.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'datathon21'...\n",
            "remote: Enumerating objects: 259, done.\u001b[K\n",
            "remote: Counting objects: 100% (259/259), done.\u001b[K\n",
            "remote: Compressing objects: 100% (191/191), done.\u001b[K\n",
            "remote: Total 259 (delta 105), reused 181 (delta 62), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (259/259), 31.67 MiB | 10.43 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6v5biTITqHs",
        "outputId": "b0400473-2ef6-430c-9c6d-aa1b2a9660b1"
      },
      "source": [
        "!cd datathon21/ && git pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "ZuePpzRpNsdl",
        "outputId": "93b1be10-9add-4580-affc-a43bdd04cbcd"
      },
      "source": [
        "!pip install --upgrade pandas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/51/48f3fc47c4e2144da2806dfb6629c4dd1fa3d5a143f9652b141e979a8ca9/pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "Successfully installed pandas-1.2.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X1_mIsvsq_8",
        "outputId": "44261e3c-732f-4dbb-9b74-976ede40b33e"
      },
      "source": [
        "pd.show_versions()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "INSTALLED VERSIONS\n",
            "------------------\n",
            "commit           : 2cb96529396d93b46abab7bbc73a208e708c642e\n",
            "python           : 3.7.10.final.0\n",
            "python-bits      : 64\n",
            "OS               : Linux\n",
            "OS-release       : 4.19.112+\n",
            "Version          : #1 SMP Thu Jul 23 08:00:38 PDT 2020\n",
            "machine          : x86_64\n",
            "processor        : x86_64\n",
            "byteorder        : little\n",
            "LC_ALL           : None\n",
            "LANG             : en_US.UTF-8\n",
            "LOCALE           : en_US.UTF-8\n",
            "\n",
            "pandas           : 1.2.4\n",
            "numpy            : 1.19.5\n",
            "pytz             : 2018.9\n",
            "dateutil         : 2.8.1\n",
            "pip              : 19.3.1\n",
            "setuptools       : 56.1.0\n",
            "Cython           : 0.29.22\n",
            "pytest           : 3.6.4\n",
            "hypothesis       : None\n",
            "sphinx           : 1.8.5\n",
            "blosc            : None\n",
            "feather          : 0.4.1\n",
            "xlsxwriter       : None\n",
            "lxml.etree       : 4.2.6\n",
            "html5lib         : 1.0.1\n",
            "pymysql          : None\n",
            "psycopg2         : 2.7.6.1 (dt dec pq3 ext lo64)\n",
            "jinja2           : 2.11.3\n",
            "IPython          : 5.5.0\n",
            "pandas_datareader: 0.9.0\n",
            "bs4              : 4.6.3\n",
            "bottleneck       : 1.3.2\n",
            "fsspec           : None\n",
            "fastparquet      : None\n",
            "gcsfs            : None\n",
            "matplotlib       : 3.2.2\n",
            "numexpr          : 2.7.3\n",
            "odfpy            : None\n",
            "openpyxl         : 2.5.9\n",
            "pandas_gbq       : 0.13.3\n",
            "pyarrow          : 3.0.0\n",
            "pyxlsb           : None\n",
            "s3fs             : None\n",
            "scipy            : 1.4.1\n",
            "sqlalchemy       : 1.4.7\n",
            "tables           : 3.4.4\n",
            "tabulate         : 0.8.9\n",
            "xarray           : 0.15.1\n",
            "xlrd             : 1.1.0\n",
            "xlwt             : 1.3.0\n",
            "numba            : 0.51.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAqlqA6IdB-a"
      },
      "source": [
        "! cp datathon21/Mo/Features_Data/Amenities_features_Train.csv Amenities_features_Train.csv"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loaJsmWjdOhR"
      },
      "source": [
        "! cp datathon21/Mo/Features_Data/Amenities_features_Test.csv Amenities_features_Test.csv"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXH03xG_dPTm"
      },
      "source": [
        "! cp datathon21/Mo/Features_Data/Part2_Amenities_features_Train.csv Part2_Amenities_features_Train.csv"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7AjQCP0dP20"
      },
      "source": [
        "! cp datathon21/Mo/Features_Data/Part2_Amenities_features_Test.csv Part2_Amenities_features_Test.csv"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_hNi1g5n8JP"
      },
      "source": [
        "! cp /content/datathon21/kei/real_estate/transportation_distance_test.csv transportation_distance_test.csv "
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUdBnyKIpW7l"
      },
      "source": [
        "! cp /content/datathon21/kei/real_estate/transportation_distance_train.csv transportation_distance_train.csv "
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUQPntyhNpo3",
        "outputId": "5b03fe10-a885-4c87-8d5f-a23184e41258"
      },
      "source": [
        "! python datathon21/kei/real_estate/preprocess_data.py "
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"datathon21/kei/real_estate/preprocess_data.py\", line 74, in <module>\n",
            "    X_train, X_test = preprocess_data(X_train, X_test)\n",
            "  File \"datathon21/kei/real_estate/preprocess_data.py\", line 63, in preprocess_data\n",
            "    X = pd.concat([X, Z], axis=1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 298, in concat\n",
            "    return op.get_result()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 516, in get_result\n",
            "    indexers[ax] = obj_labels.get_indexer(new_labels)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\", line 3172, in get_indexer\n",
            "    \"Reindexing only valid with uniquely valued Index objects\"\n",
            "pandas.errors.InvalidIndexError: Reindexing only valid with uniquely valued Index objects\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6egH1Npdwo2"
      },
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import xgboost as xgb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnVD6HcMbtqL"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers, Sequential, Model, backend as K\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, concatenate, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMZw16iXehDK",
        "outputId": "702636ee-ada2-4ada-98dd-136389e7693c"
      },
      "source": [
        "leave_out = 40000\n",
        "xgb_model = xgb.XGBRegressor(random_state=42, max_depth=10, objective='reg:squarederror', learning_rate=.1)\n",
        "xgb_model.fit(X_train_ready[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=10, min_child_weight=1, missing=None, n_estimators=100,\n",
              "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
              "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "             seed=None, silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwmtCRo82k1V",
        "outputId": "a288025a-e72d-40e6-c997-b89464c5e7ae"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(xgb_model.predict(X_train_ready[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(xgb_model.predict(X_train_ready[leave_out:]), y_train[leave_out:], squared=False))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94940.71735703977\n",
            "171599.3222388754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHuYTmjSzwNh"
      },
      "source": [
        "import lightgbm as lgb\n",
        "params = {'num_leaves': 100}\n",
        "lgb_data = lgb.Dataset(X_train_ready[:-leave_out], label=y_train[:-leave_out])\n",
        "bst = lgb.train(params, lgb_data, 100)\n",
        "# lgb.cv(param, train_data, num_round, nfold=5)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fncIKbPDI_z9",
        "outputId": "c4c22535-99c8-45c0-8873-47dae79f584d"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(bst.predict(X_train_maybe[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(bst.predict(X_train_maybe[leave_out:]), y_train[leave_out:], squared=False))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "184641.19978960682\n",
            "204701.4055561699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWgUS2UsOoec"
      },
      "source": [
        "extra_X = pd.read_csv('/content/datathon21/Mo/Features_Data/Amenities_features_Train.csv')\n",
        "X = X_train.copy()\n",
        "X['Public transport in 1km radius'] = extra_X['Public transport in 1km radius']\n",
        "X['Hospital in 1km radius'] = extra_X['Hospital in 1km radius']\n",
        "X['BeachDensity in 1km radius'] = extra_X['BeachDensity in 1km radius']\n",
        "X['Km to CBD'] = extra_X['Km to CBD']\n",
        "X['Church in 1km radius'] = extra_X['Church in 1km radius']\n",
        "X['Kindergarten in 1km radius'] = extra_X['Kindergarten in 1km radius']\n",
        "extra_X = pd.read_csv('/content/datathon21/Mo/Features_Data/Part2_Amenities_features_Train.csv')\n",
        "X['Restaurant in 1km radius'] = extra_X['Restaurant in 1km radius']\n",
        "X['Cafe in 1km radius'] = extra_X['Cafe in 1km radius']\n",
        "X['Bar in 1km radius'] = extra_X['Bar in 1km radius']\n",
        "X['Pub in 1km radius'] = extra_X['Pub in 1km radius']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRmbw5YKt3Mm"
      },
      "source": [
        "# All"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mLkNS_y1U1P",
        "outputId": "ee9cec54-525c-4125-83ca-eea52e7a180c"
      },
      "source": [
        "max(X_train['SC_tdist'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87978.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOFM0PFG0uh7",
        "outputId": "a06c80d7-b2ab-40a0-f123-a2d6dc1fa4b1"
      },
      "source": [
        "for i in range(729):\n",
        "  if X_train[X_train.columns[i]].isnull().values.any():\n",
        "    print(i)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "725\n",
            "726\n",
            "727\n",
            "728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGhoKx3d3wbu"
      },
      "source": [
        "X_train['SC_ttime'] = X_train['SC_ttime'].fillna(100000)\n",
        "X_train['SC_tdist'] = X_train['SC_tdist'].fillna(100000)\n",
        "X_train['FS_ttime'] = X_train['FS_ttime'].fillna(100000)\n",
        "X_train['FS_tdist'] = X_train['FS_tdist'].fillna(100000)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "WXwU6ZkzeYRE",
        "outputId": "4d1303d5-4e60-4152-feb2-b8606f4c2482"
      },
      "source": [
        "# X_train = pd.read_csv('X_train_preprocessed.csv')\n",
        "X_train"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Lat</th>\n",
              "      <th>long</th>\n",
              "      <th>Area</th>\n",
              "      <th>transYear</th>\n",
              "      <th>transMonth</th>\n",
              "      <th>transDays</th>\n",
              "      <th>transQtr</th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Baths</th>\n",
              "      <th>Parking</th>\n",
              "      <th>HasFirepla</th>\n",
              "      <th>HasPool</th>\n",
              "      <th>HasGarage</th>\n",
              "      <th>HasAirCond</th>\n",
              "      <th>Year</th>\n",
              "      <th>Day_of_week</th>\n",
              "      <th>Month</th>\n",
              "      <th>City_Abbotsford</th>\n",
              "      <th>City_Aberfeldie</th>\n",
              "      <th>City_Airport West</th>\n",
              "      <th>City_Albanvale</th>\n",
              "      <th>City_Albert Park</th>\n",
              "      <th>City_Albion</th>\n",
              "      <th>City_Alphington</th>\n",
              "      <th>City_Altona</th>\n",
              "      <th>City_Altona Meadows</th>\n",
              "      <th>City_Altona North</th>\n",
              "      <th>City_Ardeer</th>\n",
              "      <th>City_Armadale</th>\n",
              "      <th>City_Ascot Vale</th>\n",
              "      <th>City_Ashburton</th>\n",
              "      <th>City_Ashwood</th>\n",
              "      <th>City_Aspendale</th>\n",
              "      <th>City_Aspendale Gardens</th>\n",
              "      <th>City_Attwood</th>\n",
              "      <th>City_Avondale Heights</th>\n",
              "      <th>City_Avonsleigh</th>\n",
              "      <th>City_Bacchus Marsh</th>\n",
              "      <th>City_Balaclava</th>\n",
              "      <th>...</th>\n",
              "      <th>postCode_3796</th>\n",
              "      <th>postCode_3797</th>\n",
              "      <th>postCode_3799</th>\n",
              "      <th>postCode_3802</th>\n",
              "      <th>postCode_3803</th>\n",
              "      <th>postCode_3804</th>\n",
              "      <th>postCode_3805</th>\n",
              "      <th>postCode_3806</th>\n",
              "      <th>postCode_3807</th>\n",
              "      <th>postCode_3808</th>\n",
              "      <th>postCode_3809</th>\n",
              "      <th>postCode_3810</th>\n",
              "      <th>postCode_3910</th>\n",
              "      <th>postCode_3975</th>\n",
              "      <th>postCode_3976</th>\n",
              "      <th>postCode_3977</th>\n",
              "      <th>postCode_3980</th>\n",
              "      <th>HasPool_isna</th>\n",
              "      <th>HasGarage_isna</th>\n",
              "      <th>HasFirepla_isna</th>\n",
              "      <th>HasAirCond_isna</th>\n",
              "      <th>Parking_isna</th>\n",
              "      <th>Baths_isna</th>\n",
              "      <th>Rooms_isna</th>\n",
              "      <th>lat+long</th>\n",
              "      <th>lat-long</th>\n",
              "      <th>Public transport in 1km radius</th>\n",
              "      <th>Hospital in 1km radius</th>\n",
              "      <th>Church in 1km radius</th>\n",
              "      <th>Kindergarten in 1km radius</th>\n",
              "      <th>BeachDensity in 1km radius</th>\n",
              "      <th>Km to CBD</th>\n",
              "      <th>Restaurant in 1km radius</th>\n",
              "      <th>Cafe in 1km radius</th>\n",
              "      <th>Bar in 1km radius</th>\n",
              "      <th>Pub in 1km radius</th>\n",
              "      <th>SC_ttime</th>\n",
              "      <th>SC_tdist</th>\n",
              "      <th>FS_ttime</th>\n",
              "      <th>FS_tdist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1222750</td>\n",
              "      <td>-37.829457</td>\n",
              "      <td>145.130499</td>\n",
              "      <td>193</td>\n",
              "      <td>2010</td>\n",
              "      <td>7</td>\n",
              "      <td>198</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2010</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>107.301042</td>\n",
              "      <td>-182.959956</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28666.989723</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3125.0</td>\n",
              "      <td>18826.0</td>\n",
              "      <td>2587.0</td>\n",
              "      <td>16852.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>554800</td>\n",
              "      <td>-37.901293</td>\n",
              "      <td>145.040301</td>\n",
              "      <td>1222</td>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>107.139008</td>\n",
              "      <td>-182.941594</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28495.828853</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2110.0</td>\n",
              "      <td>15551.0</td>\n",
              "      <td>1688.0</td>\n",
              "      <td>13980.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>610280</td>\n",
              "      <td>-38.088126</td>\n",
              "      <td>145.488687</td>\n",
              "      <td>528</td>\n",
              "      <td>2011</td>\n",
              "      <td>13</td>\n",
              "      <td>379</td>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>107.400561</td>\n",
              "      <td>-183.576814</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27779.602427</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5936.0</td>\n",
              "      <td>59834.0</td>\n",
              "      <td>5454.0</td>\n",
              "      <td>58275.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>485815</td>\n",
              "      <td>-37.885781</td>\n",
              "      <td>144.776041</td>\n",
              "      <td>557</td>\n",
              "      <td>2011</td>\n",
              "      <td>12</td>\n",
              "      <td>346</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>106.890261</td>\n",
              "      <td>-182.661822</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28517.067242</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2443.0</td>\n",
              "      <td>24691.0</td>\n",
              "      <td>2621.0</td>\n",
              "      <td>26203.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>890600</td>\n",
              "      <td>-37.836286</td>\n",
              "      <td>144.943116</td>\n",
              "      <td>111</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>113</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2010</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>107.106830</td>\n",
              "      <td>-182.779402</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>28639.924684</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1151.0</td>\n",
              "      <td>3022.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>4146.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84563</th>\n",
              "      <td>1471680</td>\n",
              "      <td>-37.811613</td>\n",
              "      <td>145.123794</td>\n",
              "      <td>138</td>\n",
              "      <td>2012</td>\n",
              "      <td>31</td>\n",
              "      <td>943</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2012</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>107.312181</td>\n",
              "      <td>-182.935407</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28696.080215</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3125.0</td>\n",
              "      <td>18777.0</td>\n",
              "      <td>2583.0</td>\n",
              "      <td>17163.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84564</th>\n",
              "      <td>128480</td>\n",
              "      <td>-37.830895</td>\n",
              "      <td>145.044432</td>\n",
              "      <td>249</td>\n",
              "      <td>2011</td>\n",
              "      <td>9</td>\n",
              "      <td>271</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>107.213537</td>\n",
              "      <td>-182.875327</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28657.719247</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2579.0</td>\n",
              "      <td>9272.0</td>\n",
              "      <td>1934.0</td>\n",
              "      <td>7866.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84565</th>\n",
              "      <td>554800</td>\n",
              "      <td>-37.823592</td>\n",
              "      <td>145.244889</td>\n",
              "      <td>670</td>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>107.421297</td>\n",
              "      <td>-183.068482</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28686.124393</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3465.0</td>\n",
              "      <td>29091.0</td>\n",
              "      <td>2923.0</td>\n",
              "      <td>27501.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84566</th>\n",
              "      <td>1100110</td>\n",
              "      <td>-37.818219</td>\n",
              "      <td>145.242537</td>\n",
              "      <td>752</td>\n",
              "      <td>2011</td>\n",
              "      <td>17</td>\n",
              "      <td>490</td>\n",
              "      <td>6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>107.424318</td>\n",
              "      <td>-183.060756</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28694.895017</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3758.0</td>\n",
              "      <td>27252.0</td>\n",
              "      <td>3276.0</td>\n",
              "      <td>25756.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84567</th>\n",
              "      <td>730730</td>\n",
              "      <td>-37.482672</td>\n",
              "      <td>144.599369</td>\n",
              "      <td>682</td>\n",
              "      <td>2011</td>\n",
              "      <td>14</td>\n",
              "      <td>425</td>\n",
              "      <td>5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>107.116697</td>\n",
              "      <td>-182.082041</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28386.826969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5654.0</td>\n",
              "      <td>69477.0</td>\n",
              "      <td>6072.0</td>\n",
              "      <td>71089.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84568 rows × 729 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Date        Lat        long  ...  SC_tdist  FS_ttime  FS_tdist\n",
              "0      1222750 -37.829457  145.130499  ...   18826.0    2587.0   16852.0\n",
              "1       554800 -37.901293  145.040301  ...   15551.0    1688.0   13980.0\n",
              "2       610280 -38.088126  145.488687  ...   59834.0    5454.0   58275.0\n",
              "3       485815 -37.885781  144.776041  ...   24691.0    2621.0   26203.0\n",
              "4       890600 -37.836286  144.943116  ...    3022.0    1627.0    4146.0\n",
              "...        ...        ...         ...  ...       ...       ...       ...\n",
              "84563  1471680 -37.811613  145.123794  ...   18777.0    2583.0   17163.0\n",
              "84564   128480 -37.830895  145.044432  ...    9272.0    1934.0    7866.0\n",
              "84565   554800 -37.823592  145.244889  ...   29091.0    2923.0   27501.0\n",
              "84566  1100110 -37.818219  145.242537  ...   27252.0    3276.0   25756.0\n",
              "84567   730730 -37.482672  144.599369  ...   69477.0    6072.0   71089.0\n",
              "\n",
              "[84568 rows x 729 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "RRhtDq6Zgf1o",
        "outputId": "cecaf955-bd2b-421d-d751-85ac8166636c"
      },
      "source": [
        "# X_test = pd.read_csv('X_test_preprocessed.csv')\n",
        "X_test"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Lat</th>\n",
              "      <th>long</th>\n",
              "      <th>Area</th>\n",
              "      <th>transYear</th>\n",
              "      <th>transMonth</th>\n",
              "      <th>transDays</th>\n",
              "      <th>transQtr</th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Baths</th>\n",
              "      <th>Parking</th>\n",
              "      <th>HasFirepla</th>\n",
              "      <th>HasPool</th>\n",
              "      <th>HasGarage</th>\n",
              "      <th>HasAirCond</th>\n",
              "      <th>Year</th>\n",
              "      <th>Day_of_week</th>\n",
              "      <th>Month</th>\n",
              "      <th>City_Abbotsford</th>\n",
              "      <th>City_Aberfeldie</th>\n",
              "      <th>City_Airport West</th>\n",
              "      <th>City_Albanvale</th>\n",
              "      <th>City_Albert Park</th>\n",
              "      <th>City_Albion</th>\n",
              "      <th>City_Alphington</th>\n",
              "      <th>City_Altona</th>\n",
              "      <th>City_Altona Meadows</th>\n",
              "      <th>City_Altona North</th>\n",
              "      <th>City_Ardeer</th>\n",
              "      <th>City_Armadale</th>\n",
              "      <th>City_Ascot Vale</th>\n",
              "      <th>City_Ashburton</th>\n",
              "      <th>City_Ashwood</th>\n",
              "      <th>City_Aspendale</th>\n",
              "      <th>City_Aspendale Gardens</th>\n",
              "      <th>City_Attwood</th>\n",
              "      <th>City_Avondale Heights</th>\n",
              "      <th>City_Avonsleigh</th>\n",
              "      <th>City_Bacchus Marsh</th>\n",
              "      <th>City_Balaclava</th>\n",
              "      <th>...</th>\n",
              "      <th>postCode_3796</th>\n",
              "      <th>postCode_3797</th>\n",
              "      <th>postCode_3799</th>\n",
              "      <th>postCode_3802</th>\n",
              "      <th>postCode_3803</th>\n",
              "      <th>postCode_3804</th>\n",
              "      <th>postCode_3805</th>\n",
              "      <th>postCode_3806</th>\n",
              "      <th>postCode_3807</th>\n",
              "      <th>postCode_3808</th>\n",
              "      <th>postCode_3809</th>\n",
              "      <th>postCode_3810</th>\n",
              "      <th>postCode_3910</th>\n",
              "      <th>postCode_3975</th>\n",
              "      <th>postCode_3976</th>\n",
              "      <th>postCode_3977</th>\n",
              "      <th>postCode_3980</th>\n",
              "      <th>HasPool_isna</th>\n",
              "      <th>HasGarage_isna</th>\n",
              "      <th>HasFirepla_isna</th>\n",
              "      <th>HasAirCond_isna</th>\n",
              "      <th>Parking_isna</th>\n",
              "      <th>Baths_isna</th>\n",
              "      <th>Rooms_isna</th>\n",
              "      <th>lat+long</th>\n",
              "      <th>lat-long</th>\n",
              "      <th>Public transport in 1km radius</th>\n",
              "      <th>Hospital in 1km radius</th>\n",
              "      <th>Church in 1km radius</th>\n",
              "      <th>Kindergarten in 1km radius</th>\n",
              "      <th>BeachDensity in 1km radius</th>\n",
              "      <th>Km to CBD</th>\n",
              "      <th>Restaurant in 1km radius</th>\n",
              "      <th>Cafe in 1km radius</th>\n",
              "      <th>Bar in 1km radius</th>\n",
              "      <th>Pub in 1km radius</th>\n",
              "      <th>SC_ttime</th>\n",
              "      <th>SC_tdist</th>\n",
              "      <th>FS_ttime</th>\n",
              "      <th>FS_tdist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128480</td>\n",
              "      <td>-37.872024</td>\n",
              "      <td>145.168952</td>\n",
              "      <td>726</td>\n",
              "      <td>2011</td>\n",
              "      <td>9</td>\n",
              "      <td>267</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>107.296929</td>\n",
              "      <td>-183.040976</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28581.250782</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3467.0</td>\n",
              "      <td>24330.0</td>\n",
              "      <td>2985.0</td>\n",
              "      <td>22770.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1204500</td>\n",
              "      <td>-37.752083</td>\n",
              "      <td>145.053423</td>\n",
              "      <td>673</td>\n",
              "      <td>2012</td>\n",
              "      <td>29</td>\n",
              "      <td>870</td>\n",
              "      <td>10</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2012</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>107.301341</td>\n",
              "      <td>-182.805506</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28756.589093</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2765.0</td>\n",
              "      <td>16488.0</td>\n",
              "      <td>2883.0</td>\n",
              "      <td>18053.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>855195</td>\n",
              "      <td>-37.669419</td>\n",
              "      <td>144.588998</td>\n",
              "      <td>647</td>\n",
              "      <td>2011</td>\n",
              "      <td>15</td>\n",
              "      <td>452</td>\n",
              "      <td>5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>106.919580</td>\n",
              "      <td>-182.258417</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28727.395209</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4539.0</td>\n",
              "      <td>45580.0</td>\n",
              "      <td>5857.0</td>\n",
              "      <td>45524.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000100</td>\n",
              "      <td>-37.756833</td>\n",
              "      <td>144.746616</td>\n",
              "      <td>448</td>\n",
              "      <td>2010</td>\n",
              "      <td>5</td>\n",
              "      <td>149</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>106.989783</td>\n",
              "      <td>-182.503449</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28729.092966</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2636.0</td>\n",
              "      <td>23606.0</td>\n",
              "      <td>4063.0</td>\n",
              "      <td>25785.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>670140</td>\n",
              "      <td>-37.860910</td>\n",
              "      <td>145.319344</td>\n",
              "      <td>1032</td>\n",
              "      <td>2012</td>\n",
              "      <td>25</td>\n",
              "      <td>733</td>\n",
              "      <td>9</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2012</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>107.458434</td>\n",
              "      <td>-183.180254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28618.471102</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5755.0</td>\n",
              "      <td>38903.0</td>\n",
              "      <td>5153.0</td>\n",
              "      <td>37319.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41648</th>\n",
              "      <td>1340280</td>\n",
              "      <td>-37.790912</td>\n",
              "      <td>144.995977</td>\n",
              "      <td>224</td>\n",
              "      <td>2012</td>\n",
              "      <td>30</td>\n",
              "      <td>894</td>\n",
              "      <td>10</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2012</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>107.205065</td>\n",
              "      <td>-182.786889</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>28714.777186</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1446.0</td>\n",
              "      <td>8507.0</td>\n",
              "      <td>1564.0</td>\n",
              "      <td>10072.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41649</th>\n",
              "      <td>402960</td>\n",
              "      <td>-37.973567</td>\n",
              "      <td>145.160623</td>\n",
              "      <td>591</td>\n",
              "      <td>2012</td>\n",
              "      <td>23</td>\n",
              "      <td>682</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2012</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>107.187056</td>\n",
              "      <td>-183.134190</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28268.684369</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3828.0</td>\n",
              "      <td>28590.0</td>\n",
              "      <td>2986.0</td>\n",
              "      <td>27042.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41650</th>\n",
              "      <td>1224575</td>\n",
              "      <td>-37.870497</td>\n",
              "      <td>145.036959</td>\n",
              "      <td>474</td>\n",
              "      <td>2011</td>\n",
              "      <td>18</td>\n",
              "      <td>530</td>\n",
              "      <td>6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>107.166462</td>\n",
              "      <td>-182.907456</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28574.707238</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2138.0</td>\n",
              "      <td>11454.0</td>\n",
              "      <td>1716.0</td>\n",
              "      <td>9883.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41651</th>\n",
              "      <td>664300</td>\n",
              "      <td>-37.690474</td>\n",
              "      <td>144.553736</td>\n",
              "      <td>375</td>\n",
              "      <td>2010</td>\n",
              "      <td>2</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2010</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>106.863262</td>\n",
              "      <td>-182.244210</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28732.069328</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4575.0</td>\n",
              "      <td>41469.0</td>\n",
              "      <td>4873.0</td>\n",
              "      <td>43049.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41652</th>\n",
              "      <td>1073100</td>\n",
              "      <td>-37.770674</td>\n",
              "      <td>145.063068</td>\n",
              "      <td>1019</td>\n",
              "      <td>2012</td>\n",
              "      <td>28</td>\n",
              "      <td>845</td>\n",
              "      <td>10</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2012</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>107.292394</td>\n",
              "      <td>-182.833742</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28742.167894</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2210.0</td>\n",
              "      <td>15221.0</td>\n",
              "      <td>2328.0</td>\n",
              "      <td>16778.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41653 rows × 729 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Date        Lat        long  ...  SC_tdist  FS_ttime  FS_tdist\n",
              "0       128480 -37.872024  145.168952  ...   24330.0    2985.0   22770.0\n",
              "1      1204500 -37.752083  145.053423  ...   16488.0    2883.0   18053.0\n",
              "2       855195 -37.669419  144.588998  ...   45580.0    5857.0   45524.0\n",
              "3      1000100 -37.756833  144.746616  ...   23606.0    4063.0   25785.0\n",
              "4       670140 -37.860910  145.319344  ...   38903.0    5153.0   37319.0\n",
              "...        ...        ...         ...  ...       ...       ...       ...\n",
              "41648  1340280 -37.790912  144.995977  ...    8507.0    1564.0   10072.0\n",
              "41649   402960 -37.973567  145.160623  ...   28590.0    2986.0   27042.0\n",
              "41650  1224575 -37.870497  145.036959  ...   11454.0    1716.0    9883.0\n",
              "41651   664300 -37.690474  144.553736  ...   41469.0    4873.0   43049.0\n",
              "41652  1073100 -37.770674  145.063068  ...   15221.0    2328.0   16778.0\n",
              "\n",
              "[41653 rows x 729 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA9niLqa4ycX"
      },
      "source": [
        "X_test['SC_ttime'] = X_test['SC_ttime'].fillna(100000)\n",
        "X_test['SC_tdist'] = X_test['SC_tdist'].fillna(100000)\n",
        "X_test['FS_ttime'] = X_test['FS_ttime'].fillna(100000)\n",
        "X_test['FS_tdist'] = X_test['FS_tdist'].fillna(100000)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "w8LX6E0NgEIb",
        "outputId": "31d909a9-a5b5-4bdb-9948-a4094bf97a38"
      },
      "source": [
        "y_train = pd.read_csv('y_train.csv')\n",
        "y_train.drop('Id', axis=1, inplace=True)\n",
        "y_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>365000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>608000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>787000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84563</th>\n",
              "      <td>430000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84564</th>\n",
              "      <td>826000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84565</th>\n",
              "      <td>505000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84566</th>\n",
              "      <td>410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84567</th>\n",
              "      <td>420000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84568 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Price\n",
              "0      500000\n",
              "1      540000\n",
              "2      365000\n",
              "3      608000\n",
              "4      787000\n",
              "...       ...\n",
              "84563  430000\n",
              "84564  826000\n",
              "84565  505000\n",
              "84566  410000\n",
              "84567  420000\n",
              "\n",
              "[84568 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_NcgYeVZh8B",
        "outputId": "3b81347d-f0da-4e02-86be-0d2b92d95fdf"
      },
      "source": [
        "!cd datathon21/ && git pull"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 8 (delta 2), reused 8 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (8/8), done.\n",
            "From https://github.com/ixil/datathon21\n",
            "   444b85f..85243fb  main       -> origin/main\n",
            "Updating 444b85f..85243fb\n",
            "Fast-forward\n",
            " kei/real_estate/y_test_lgb.csv  |  83306 \u001b[32m+++++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " kei/real_estate/y_test_xgb.csv  |  83306 \u001b[32m+++++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " kei/real_estate/y_train_lgb.csv | 169136 \u001b[32m++++++++++++++++++\u001b[m\u001b[31m-------------------\u001b[m\n",
            " kei/real_estate/y_train_xgb.csv | 169136 \u001b[32m++++++++++++++++++\u001b[m\u001b[31m-------------------\u001b[m\n",
            " 4 files changed, 252442 insertions(+), 252442 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "Rm9uMVZQa2Ye",
        "outputId": "ea4b45be-5e66-4ea9-9260-d7aeb2c4870b"
      },
      "source": [
        "y_train_xgb = pd.read_csv('datathon21/kei/real_estate/y_train_xgb.csv')\n",
        "y_train_xgb"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>616199.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>465686.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>357860.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>539820.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>716435.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84563</th>\n",
              "      <td>84563</td>\n",
              "      <td>486119.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84564</th>\n",
              "      <td>84564</td>\n",
              "      <td>965218.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84565</th>\n",
              "      <td>84565</td>\n",
              "      <td>523642.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84566</th>\n",
              "      <td>84566</td>\n",
              "      <td>373905.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84567</th>\n",
              "      <td>84567</td>\n",
              "      <td>385503.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84568 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id  Predicted\n",
              "0          0  616199.56\n",
              "1          1  465686.62\n",
              "2          2  357860.40\n",
              "3          3  539820.80\n",
              "4          4  716435.60\n",
              "...      ...        ...\n",
              "84563  84563  486119.30\n",
              "84564  84564  965218.44\n",
              "84565  84565  523642.22\n",
              "84566  84566  373905.34\n",
              "84567  84567  385503.20\n",
              "\n",
              "[84568 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "I4PEvOzea4lZ",
        "outputId": "c4f05497-fa20-4440-ecfd-13718c606d3a"
      },
      "source": [
        "y_test_xgb = pd.read_csv('datathon21/kei/real_estate/y_test_xgb.csv')\n",
        "y_test_xgb"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>736040.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>580818.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>299750.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>415894.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>482075.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41648</th>\n",
              "      <td>41648</td>\n",
              "      <td>1038133.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41649</th>\n",
              "      <td>41649</td>\n",
              "      <td>374854.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41650</th>\n",
              "      <td>41650</td>\n",
              "      <td>1235933.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41651</th>\n",
              "      <td>41651</td>\n",
              "      <td>263821.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41652</th>\n",
              "      <td>41652</td>\n",
              "      <td>1485509.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41653 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id   Predicted\n",
              "0          0   736040.80\n",
              "1          1   580818.56\n",
              "2          2   299750.22\n",
              "3          3   415894.38\n",
              "4          4   482075.10\n",
              "...      ...         ...\n",
              "41648  41648  1038133.10\n",
              "41649  41649   374854.38\n",
              "41650  41650  1235933.80\n",
              "41651  41651   263821.00\n",
              "41652  41652  1485509.50\n",
              "\n",
              "[41653 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "evMP7fleZ6Qy",
        "outputId": "1ba8f981-2883-47eb-fcdf-aa419bc94909"
      },
      "source": [
        "y_train_lgb = pd.read_csv('datathon21/kei/real_estate/y_train_lgb.csv')\n",
        "y_train_lgb"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>671665.693639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>423884.941596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>351601.860235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>564931.216105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>709920.827156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84563</th>\n",
              "      <td>84563</td>\n",
              "      <td>424687.177793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84564</th>\n",
              "      <td>84564</td>\n",
              "      <td>959096.392240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84565</th>\n",
              "      <td>84565</td>\n",
              "      <td>548242.691936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84566</th>\n",
              "      <td>84566</td>\n",
              "      <td>375437.904870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84567</th>\n",
              "      <td>84567</td>\n",
              "      <td>387585.514946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84568 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id      Predicted\n",
              "0          0  671665.693639\n",
              "1          1  423884.941596\n",
              "2          2  351601.860235\n",
              "3          3  564931.216105\n",
              "4          4  709920.827156\n",
              "...      ...            ...\n",
              "84563  84563  424687.177793\n",
              "84564  84564  959096.392240\n",
              "84565  84565  548242.691936\n",
              "84566  84566  375437.904870\n",
              "84567  84567  387585.514946\n",
              "\n",
              "[84568 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "Hztya2aXaIP-",
        "outputId": "dbf3e670-d659-4147-fc58-62fa9ff444fc"
      },
      "source": [
        "y_test_lgb = pd.read_csv('datathon21/kei/real_estate/y_test_lgb.csv')\n",
        "y_test_lgb"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7.689544e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5.457401e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.669088e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4.349158e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.486747e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41648</th>\n",
              "      <td>41648</td>\n",
              "      <td>9.821705e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41649</th>\n",
              "      <td>41649</td>\n",
              "      <td>3.623806e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41650</th>\n",
              "      <td>41650</td>\n",
              "      <td>1.275953e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41651</th>\n",
              "      <td>41651</td>\n",
              "      <td>2.748869e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41652</th>\n",
              "      <td>41652</td>\n",
              "      <td>1.344934e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41653 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id     Predicted\n",
              "0          0  7.689544e+05\n",
              "1          1  5.457401e+05\n",
              "2          2  2.669088e+05\n",
              "3          3  4.349158e+05\n",
              "4          4  4.486747e+05\n",
              "...      ...           ...\n",
              "41648  41648  9.821705e+05\n",
              "41649  41649  3.623806e+05\n",
              "41650  41650  1.275953e+06\n",
              "41651  41651  2.748869e+05\n",
              "41652  41652  1.344934e+06\n",
              "\n",
              "[41653 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "uOcftytqRzcf",
        "outputId": "8804dfea-048d-425f-9e3b-a53d255b4083"
      },
      "source": [
        "y_train_catboost = pd.read_csv('datathon21/Mo/Predictions/prediction_CatBoost_Train.csv')\n",
        "y_train_catboost"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>592974.988677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>420345.098643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>365369.358989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>554814.194466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>775183.217339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84563</th>\n",
              "      <td>84563</td>\n",
              "      <td>455324.469460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84564</th>\n",
              "      <td>84564</td>\n",
              "      <td>992039.690917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84565</th>\n",
              "      <td>84565</td>\n",
              "      <td>518928.625571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84566</th>\n",
              "      <td>84566</td>\n",
              "      <td>370842.576429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84567</th>\n",
              "      <td>84567</td>\n",
              "      <td>365114.393343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84568 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id     Prediction\n",
              "0          0  592974.988677\n",
              "1          1  420345.098643\n",
              "2          2  365369.358989\n",
              "3          3  554814.194466\n",
              "4          4  775183.217339\n",
              "...      ...            ...\n",
              "84563  84563  455324.469460\n",
              "84564  84564  992039.690917\n",
              "84565  84565  518928.625571\n",
              "84566  84566  370842.576429\n",
              "84567  84567  365114.393343\n",
              "\n",
              "[84568 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "QKtl2BHBaQFx",
        "outputId": "c7a14699-f32f-4831-a7d3-a080efac57b2"
      },
      "source": [
        "y_test_catboost = pd.read_csv('datathon21/Mo/Predictions/prediciton_CatBoost_Test.csv')\n",
        "y_test_catboost"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7.633784e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5.542637e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.857076e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4.388373e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.971980e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41648</th>\n",
              "      <td>41648</td>\n",
              "      <td>1.037631e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41649</th>\n",
              "      <td>41649</td>\n",
              "      <td>3.807966e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41650</th>\n",
              "      <td>41650</td>\n",
              "      <td>1.302650e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41651</th>\n",
              "      <td>41651</td>\n",
              "      <td>2.951347e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41652</th>\n",
              "      <td>41652</td>\n",
              "      <td>1.342438e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41653 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id     Predicted\n",
              "0          0  7.633784e+05\n",
              "1          1  5.542637e+05\n",
              "2          2  2.857076e+05\n",
              "3          3  4.388373e+05\n",
              "4          4  4.971980e+05\n",
              "...      ...           ...\n",
              "41648  41648  1.037631e+06\n",
              "41649  41649  3.807966e+05\n",
              "41650  41650  1.302650e+06\n",
              "41651  41651  2.951347e+05\n",
              "41652  41652  1.342438e+06\n",
              "\n",
              "[41653 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM8SG3IdbVjh",
        "outputId": "8b06313c-5d7e-4ae7-a058-42d96477733c"
      },
      "source": [
        "y_train_pred = np.array([y_train_catboost['Prediction'].to_numpy(),\n",
        "                        y_train_lgb['Predicted'].to_numpy(),\n",
        "                        y_train_xgb['Predicted'].to_numpy()]).T\n",
        "y_train_pred.shape"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84568, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK9TQVsxdwkZ",
        "outputId": "117f83de-8a80-4cf5-8a88-ecd872410226"
      },
      "source": [
        "y_test_pred = np.array([y_test_catboost['Predicted'].to_numpy(),\n",
        "                        y_test_lgb['Predicted'].to_numpy(),\n",
        "                        y_test_xgb['Predicted'].to_numpy()]).T\n",
        "y_test_pred.shape"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41653, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C16Zd-VccMyw",
        "outputId": "aa0b57cd-a1e3-41f6-e346-009dbb8cec99"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84568, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "OwCqEM7ScPDa",
        "outputId": "de1f45ef-f81e-4eca-c30c-66102a2c5cbb"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>365000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>608000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>787000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84563</th>\n",
              "      <td>430000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84564</th>\n",
              "      <td>826000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84565</th>\n",
              "      <td>505000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84566</th>\n",
              "      <td>410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84567</th>\n",
              "      <td>420000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84568 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Price\n",
              "0      500000\n",
              "1      540000\n",
              "2      365000\n",
              "3      608000\n",
              "4      787000\n",
              "...       ...\n",
              "84563  430000\n",
              "84564  826000\n",
              "84565  505000\n",
              "84566  410000\n",
              "84567  420000\n",
              "\n",
              "[84568 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XuwL9Meh2kr"
      },
      "source": [
        "dy_train_pred = y_train_pred - y_train['Price'].to_numpy().reshape((-1, 1))\n",
        "Cov = dy_train_pred.T @ dy_train_pred\n",
        "weights = Cov @ np.ones([3, 1])\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiYV7UV4jNiY",
        "outputId": "e2dbf233-bf35-45fb-8c56-f1d86a82520e"
      },
      "source": [
        "weights /= np.sum(weights)\n",
        "np.sum(weights)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHRWyvgMjkSq"
      },
      "source": [
        "y_test_a = weights[0]*y_test_catboost['Predicted'].to_numpy() + \\\n",
        "            weights[1]*y_test_lgb['Predicted'].to_numpy() + \\\n",
        "            weights[2]*y_test_xgb['Predicted'].to_numpy()"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A9OH0WzahsK",
        "outputId": "6916c68d-b57d-4e66-a5ce-1966e9cd0432"
      },
      "source": [
        "# king_gb = GradientBoostingRegressor(random_state=42, max_depth=3, n_estimators=10)\n",
        "# king_gb.fit(y_stack, y_train[-leave_out:-5000])\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "lr.fit(y_train_pred, y_train)\n",
        "# from sklearn import linear_model\n",
        "# clf = linear_model.Lasso(alpha=0.1)\n",
        "# clf.fit(y_train_pred, y_train)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCB6JsgEf9-h"
      },
      "source": [
        "scaler = MinMaxScaler((0,1))\n",
        "nnn_x = scaler.fit_transform(y_train_pred)\n",
        "nnn_y = scaler.fit_transform(y_train)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGpbdWDMfpHh",
        "outputId": "e5842552-102a-4ac4-d75e-a2103c4f8530"
      },
      "source": [
        "nnn = nn(3, 1, 1, 128)\n",
        "nnn.fit(nnn_x, nnn_y, epochs=5)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2643/2643 [==============================] - 4s 1ms/step - loss: 0.0018 - MSE: 0.0018\n",
            "Epoch 2/5\n",
            "2643/2643 [==============================] - 3s 1ms/step - loss: 7.2199e-04 - MSE: 7.2199e-04\n",
            "Epoch 3/5\n",
            "2643/2643 [==============================] - 3s 1ms/step - loss: 7.0449e-04 - MSE: 7.0449e-04\n",
            "Epoch 4/5\n",
            "2643/2643 [==============================] - 3s 1ms/step - loss: 7.2408e-04 - MSE: 7.2408e-04\n",
            "Epoch 5/5\n",
            "2643/2643 [==============================] - 3s 1ms/step - loss: 7.2016e-04 - MSE: 7.2016e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2c623ac590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re6HY8P-gagV"
      },
      "source": [
        "nnn_pred = nnn.predict(scaler.fit_transform(y_test_pred))"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4FVxF4AhIUY",
        "outputId": "c991b833-62e9-46a3-9097-e9629b6304c4"
      },
      "source": [
        "nnn.predict(scaler.fit_transform(y_test_pred)).shape"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41653, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "ntL48ssng8vc",
        "outputId": "77d13076-991c-465a-c763-37f6867555e2"
      },
      "source": [
        "temp2 = scaler.inverse_transform(nn_model.predict(nn_x_train[-leave_out:]))\n",
        "# print(sklearn.metrics.mean_squared_error(temp1,\n",
        "#                                          y_train[:-leave_out], squared=False))\n",
        "# print(sklearn.metrics.mean_squared_error(temp2,\n",
        "#                                          y_train[-leave_out:], squared=False))"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-155-047a1524fb1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_x_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mleave_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(sklearn.metrics.mean_squared_error(temp1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#                                          y_train[:-leave_out], squared=False))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(sklearn.metrics.mean_squared_error(temp2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#                                          y_train[-leave_out:], squared=False))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    434\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (50000,1) doesn't match the broadcast shape (50000,3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "dW0kAFgsgjaU",
        "outputId": "79a22a90-52fe-4b4f-a6ad-335ee7f07106"
      },
      "source": [
        "nnn_pred_y = scaler.inverse_transform(nnn_pred)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-723b1c334009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnnn_pred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnn_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    434\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (41653,1) doesn't match the broadcast shape (41653,3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMIo21Knc0ty",
        "outputId": "19fe5891-57fe-4bc0-db97-ac8b376c5ba4"
      },
      "source": [
        "lr.coef_, clf.coef_"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.17775419, -0.06882548,  0.94697134]]),\n",
              " array([ 0.1777537 , -0.06882469,  0.94697105]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26lgGmF2ehJx",
        "outputId": "36183d7e-3bf0-4dba-f468-9c60ff492354"
      },
      "source": [
        "np.mean(y_train_pred, axis=1).shape"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84568,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YmFw82qdQcp",
        "outputId": "451a321b-9cea-48b2-e2cc-27a109089885"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(y_train_xgb['Predicted'], y_train, squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(lr.predict(y_train_pred), y_train, squared=False)) \n",
        "print(sklearn.metrics.mean_squared_error(np.mean(y_train_pred, axis=1), y_train, squared=False))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105131.66475576098\n",
            "103087.44305243994\n",
            "107747.20937232873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAXZFs4Vd6Sj"
      },
      "source": [
        "y_test_stack = lr.predict(y_test_pred)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEi9Z1R_eBey",
        "outputId": "1b81c1c1-44e3-459c-f15e-260d27ada218"
      },
      "source": [
        "y_test_stack.shape, "
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41653, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Tt48dUhmnY"
      },
      "source": [
        "y_test = pd.DataFrame({'Id':np.arange(41653)})\n",
        "y_test['Predicted'] = y_test_a # np.mean(y_test_pred, axis=1) # y_test_stack\n",
        "y_test.to_csv(\"./y_test_stack.csv\", index=False)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNuS9emmNsfV",
        "outputId": "a23d3dcb-ab60-484c-c712-12e5807efad9"
      },
      "source": [
        "# xgb_model = xgb.XGBRegressor(random_state=42, max_depth=10, objective='reg:squarederror')\n",
        "\n",
        "import lightgbm as lgb\n",
        "# params = {'num_leaves': 100}\n",
        "# lgb_data = lgb.Dataset(X_train_ready, label=y_train)\n",
        "# bst = lgb.train(params, lgb_data, 100)\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "# sk_gbm = GradientBoostingRegressor(random_state=42, max_depth=10)\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# regr = RandomForestRegressor(max_depth=10, random_state=42)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# lr = LinearRegression()\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "# svr = SVR(max_iter=1000, kernel='rbf')\n",
        "# svr = SVR(max_iter=1000, kernel='poly')\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "# regr = ElasticNet(random_state=42, max_iter=1000)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# knn = KNeighborsRegressor(5)\n",
        "# knn.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])\n",
        "leave_out = 20000\n",
        "ensemble = [xgb.XGBRegressor(random_state=42, max_depth=1, objective='reg:squarederror'),\n",
        "            xgb.XGBRegressor(random_state=42, max_depth=2, objective='reg:squarederror'),\n",
        "            xgb.XGBRegressor(random_state=42, max_depth=3, objective='reg:squarederror'),\n",
        "            xgb.XGBRegressor(random_state=42, max_depth=2, objective='reg:squarederror', n_estimators=110),\n",
        "            GradientBoostingRegressor(random_state=42, max_depth=9, n_estimators=100),\n",
        "            GradientBoostingRegressor(random_state=42, max_depth=10, n_estimators=100),\n",
        "            GradientBoostingRegressor(random_state=42, max_depth=11, n_estimators=100),\n",
        "            RandomForestRegressor(max_depth=3, random_state=42),\n",
        "            RandomForestRegressor(max_depth=2, random_state=42),\n",
        "            RandomForestRegressor(max_depth=1, random_state=42),\n",
        "            LinearRegression(),\n",
        "            KNeighborsRegressor(1),\n",
        "            ]\n",
        "y_stack = []\n",
        "for i,model in enumerate(ensemble):\n",
        "  print('-----------------------------------------------------')\n",
        "  if i > 3:\n",
        "    model.fit(X_train[:-leave_out], y_train[:-leave_out])\n",
        "    y_stack.append(model.predict(X_train[-leave_out:-10000]).reshape(10000))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMnHFwfYa2Eq",
        "outputId": "301843cc-4535-4dbf-91da-0ddd0f128ea2"
      },
      "source": [
        "y_stack"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([672281.57373907, 261971.6268383 , 867850.56503761, ...,\n",
              "        393996.89686443, 916651.56733757, 883583.92216106]),\n",
              " array([699243.80664693, 261124.49321655, 839494.40049238, ...,\n",
              "        368706.31201888, 977469.6286027 , 815748.20126062]),\n",
              " array([681216.01866626, 250467.24864168, 846232.86625492, ...,\n",
              "        379741.98217134, 914491.23076529, 681237.13261103]),\n",
              " array([ 691398.50000678,  408933.84830378,  691398.50000678, ...,\n",
              "         450409.54568442, 1125160.19398027,  784140.02444578]),\n",
              " array([913709.90108968, 438969.30523698, 913709.90108968, ...,\n",
              "        473764.79749096, 913709.90108968, 546704.68302505]),\n",
              " array([783939.49676173, 476604.36725423, 783939.49676173, ...,\n",
              "        476604.36725423, 783939.49676173, 783939.49676173]),\n",
              " array([ 697882.3125,  293187.625 ,  836290.4375, ...,  364558.3125,\n",
              "        1091136.4375,  652807.875 ]),\n",
              " array([600000., 290000., 550000., ..., 482500., 953000., 669000.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be7gUYVlanbh"
      },
      "source": [
        "i = -4\n",
        "y_stack[i] = y_stack[i].reshape(10000)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV7cfAV4a7s_"
      },
      "source": [
        "y_stack = np.array(y_stack).T"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epd2BGW9bBeR",
        "outputId": "97d7fc30-3a65-4a75-be34-6b277fb1fd1f"
      },
      "source": [
        "y_stack.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "maF02dkPbIY8",
        "outputId": "761fa59f-75e0-4b3d-dd28-83fa5e54c11c"
      },
      "source": [
        "y_stack_val = []\n",
        "for model in ensemble:\n",
        "  print('-----------------------------------------------------')\n",
        "  y_stack_val.append(model.predict(X_train[-10000:]).reshape(10000))\n",
        "y_stack_val = np.array(y_stack_val).T\n",
        "y_stack_val.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "XGBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-cef102cfffbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0my_stack_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_stack_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_stack_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_stack_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mntree_limit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mntree_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_ntree_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         return self.get_booster().predict(test_dmatrix,\n\u001b[0m\u001b[1;32m    454\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                                           \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXGBoostError\u001b[0m: need to call fit or load_model beforehand"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "cN_F5gPcfrjP",
        "outputId": "f4e209db-c661-4577-e6f2-a4ba01d49f9e"
      },
      "source": [
        "y_stack_big = []\n",
        "for model in ensemble:\n",
        "  print('-----------------------------------------------------')\n",
        "  y_stack_big.append(model.predict(X_train[:-leave_out]).reshape(64568))\n",
        "y_stack_big = np.array(y_stack_big).T\n",
        "y_stack_big.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-ef02c92e2db6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0my_stack_big\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mleave_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64568\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_stack_big\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_stack_big\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_stack_big\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m         \"\"\"\n\u001b[0;32m-> 2567\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2568\u001b[0m         \u001b[0;31m# In regression we can directly return the raw value from the trees.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2569\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoeQV9y1g9to",
        "outputId": "3ae0155b-3ae4-4511-8c58-143c8972b242"
      },
      "source": [
        "y_stack_test = []\n",
        "for model in ensemble:\n",
        "  print('-----------------------------------------------------')\n",
        "  y_stack_test.append(model.predict(X_).reshape(41653))\n",
        "y_stack_test = np.array(y_stack_test).T\n",
        "y_stack_test.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41653, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seAKXu8mhbVH",
        "outputId": "d7d5c2ca-3f22-4771-a826-32c4776c92e2"
      },
      "source": [
        "y_test_pred = clf.predict(y_stack_test)\n",
        "y_test_pred.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41653,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "fzz_D0cLh4Xm",
        "outputId": "7aef6dfe-fcd8-4d53-b85f-da7df47f72c1"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7.386752e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5.353136e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.886021e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4.115716e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.960636e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41648</th>\n",
              "      <td>41648</td>\n",
              "      <td>9.657294e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41649</th>\n",
              "      <td>41649</td>\n",
              "      <td>3.830171e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41650</th>\n",
              "      <td>41650</td>\n",
              "      <td>1.301770e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41651</th>\n",
              "      <td>41651</td>\n",
              "      <td>2.672885e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41652</th>\n",
              "      <td>41652</td>\n",
              "      <td>1.440183e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41653 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id     Predicted\n",
              "0          0  7.386752e+05\n",
              "1          1  5.353136e+05\n",
              "2          2  2.886021e+05\n",
              "3          3  4.115716e+05\n",
              "4          4  4.960636e+05\n",
              "...      ...           ...\n",
              "41648  41648  9.657294e+05\n",
              "41649  41649  3.830171e+05\n",
              "41650  41650  1.301770e+06\n",
              "41651  41651  2.672885e+05\n",
              "41652  41652  1.440183e+06\n",
              "\n",
              "[41653 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "2RP2T5o3f9-5",
        "outputId": "dd761aa9-fedd-448d-bfb2-4971cca3f31b"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(clf.predict(y_stack_big), y_train[:-leave_out], squared=False))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-e7c9e3373e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_stack_big\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mleave_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \"\"\"\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    792\u001b[0m                                    dense_output=True) + self.intercept_\n\u001b[1;32m    793\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 209\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 64568)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "E6Hryfhqbf-h",
        "outputId": "aac6e6a8-3f8e-47a3-e712-4c8110d59020"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(clf.predict(y_stack), y_train[-leave_out:-10000], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(clf.predict(y_stack_val), y_train[-10000:], squared=False))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175123.92573157328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-4d4a01cf589a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mleave_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_stack_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \"\"\"\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    792\u001b[0m                                    dense_output=True) + self.intercept_\n\u001b[1;32m    793\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m    209\u001b[0m                                dense_output=True) + self.intercept_\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6LDLbcjE3CB",
        "outputId": "9f89ad5c-c626-4b6b-fb57-a738a3dfd20c"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "sk_gbm = GradientBoostingRegressor(random_state=42, max_depth=10, n_estimators=100)\n",
        "sk_gbm.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=0.1, loss='ls', max_depth=10,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=42, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj9i57DWTSue",
        "outputId": "876e65ff-c5ff-4ab9-ecb0-ef3c9516f636"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(sk_gbm.predict(X_train_maybe[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(sk_gbm.predict(X_train_maybe[leave_out:]), y_train[leave_out:], squared=False))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99809.31858605916\n",
            "179192.73188021625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iEhIo08Ujgt",
        "outputId": "7dd9c751-3667-4602-c044-dd9302b266a8"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regr = RandomForestRegressor(max_depth=10, random_state=42)\n",
        "regr.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbFL9aavVBNL",
        "outputId": "56286ff6-c7bd-48f2-9f64-90b97ff492f6"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(regr.predict(X_train_maybe[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(regr.predict(X_train_maybe[leave_out:]), y_train[leave_out:], squared=False))"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "197079.41846584243\n",
            "212389.62254839923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQTdTLuH66vp",
        "outputId": "a336dda5-52a4-424e-87f0-8858431edb4c"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOUGnEmsVpXM",
        "outputId": "06db5b60-81b8-4b6f-e31c-61bb42ef2e07"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(lr.predict(X_train_maybe[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(lr.predict(X_train_maybe[leave_out:]), y_train[leave_out:], squared=False))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "236325.0698770643\n",
            "235733.80271030831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1kjMz_ElW9A",
        "outputId": "960008d0-1fcd-4076-dfe5-02692d7211e8"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "knn = KNeighborsRegressor(5)\n",
        "knn.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                    weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PLoREDolimY",
        "outputId": "c1f17632-b8cf-4d59-e531-8958ebe68f69"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(knn.predict(X_train_maybe[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(knn.predict(X_train_maybe[leave_out:]), y_train[leave_out:], squared=False))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "277857.0933105523\n",
            "333816.989267614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIuWj_sHVvY7",
        "outputId": "022b15a1-b151-4b66-c620-c90f50681dd1"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "svr = SVR(max_iter=1000, kernel='rbf')\n",
        "svr.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
              "    kernel='rbf', max_iter=1000, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czuf7Zl0WGUS",
        "outputId": "e94d95e0-9515-4cbc-e6e9-278ed9e17b48"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(svr.predict(X_train_maybe[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(svr.predict(X_train_maybe[leave_out:]), y_train[leave_out:], squared=False))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "629001.8326015454\n",
            "627749.1708672319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql4cTaIgL4Ca",
        "outputId": "1da9755a-f31e-4e82-cff3-d98ab347c271"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "svr = SVR(max_iter=1000, kernel='poly')\n",
        "svr.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
              "    kernel='poly', max_iter=1000, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5za5rD4fL4pi",
        "outputId": "b82ee9b6-526d-464e-ca38-f91cc1da42c6"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(svr.predict(X_train_maybe[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(svr.predict(X_train_maybe[leave_out:]), y_train[leave_out:], squared=False))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "628964.8035077819\n",
            "627711.9862902322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgXVPYxjLM4O",
        "outputId": "2079382a-6306-45f0-bcf6-50ada9628c05"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "regr = ElasticNet(random_state=42, max_iter=1000)\n",
        "regr.fit(X_train_maybe, y_train)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
              "           max_iter=10000, normalize=False, positive=False, precompute=False,\n",
              "           random_state=42, selection='cyclic', tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSGPBjlQLcXj",
        "outputId": "67fadfd6-c6e7-4a01-d3b9-db37594372d3"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(regr.predict(X_train_maybe[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(regr.predict(X_train_maybe[leave_out:]), y_train[leave_out:], squared=False))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "362781.5967797893\n",
            "360125.25225522637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiZD-BwGMKT7"
      },
      "source": [
        "Let's start stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IkoB1saWMlM"
      },
      "source": [
        "leave_out = 20000"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0hPJNIYTgMy",
        "outputId": "bd051ca2-8458-436b-c977-bc3a00ce91b2"
      },
      "source": [
        "# XGBOOST MODELS\n",
        "# xgb_model = xgb.XGBRegressor(random_state=42, max_depth=10, objective='reg:squarederror', n_estimators=30)\n",
        "# xgb_model.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])\n",
        "\n",
        "xgb_model1 = xgb.XGBRegressor(random_state=42, max_depth=9, objective='reg:squarederror', learning_rate=0.075, n_estimators=50)\n",
        "xgb_model1.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])\n",
        "\n",
        "# xgb_model2 = xgb.XGBRegressor(random_state=42, max_depth=10, objective='reg:squarederror', learning_rate=0.075, n_estimators=50)\n",
        "# xgb_model2.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.075, max_delta_step=0,\n",
              "             max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
              "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
              "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "             seed=None, silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW3Q6G_YxB2_",
        "outputId": "b0a04e28-2768-4b4e-d2bf-d45eed6856a1"
      },
      "source": [
        "knn = KNeighborsRegressor(5)\n",
        "knn.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                    weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rF4KKm-yc_m",
        "outputId": "d6835cb5-2dfc-4069-a1d1-0af41ce2a0a4"
      },
      "source": [
        "knn1 = KNeighborsRegressor(2)\n",
        "knn1.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                    metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
              "                    weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-Qz9jwLT4T5",
        "outputId": "449f2f0b-2455-415f-ef12-6ee536be3b92"
      },
      "source": [
        "# LightGBM MODELS - FAST FAST !!\n",
        "bst = lgb.train({'num_leaves': 100}, lgb.Dataset(X_train_maybe[:-leave_out], label=y_train[:-leave_out]), num_boost_round=100)\n",
        "bst1 = lgb.train({'num_leaves': 100, 'learning_rate': 0.1, 'num_iterations': 100}, \\\n",
        "                 lgb.Dataset(X_train_maybe[:-leave_out], label=y_train[:-leave_out]), num_boost_round=200)\n",
        "bst2 = lgb.train({'num_leaves': 100, 'learning_rate': 0.1, 'num_iterations': 110}, \\\n",
        "                 lgb.Dataset(X_train_maybe[:-leave_out], label=y_train[:-leave_out]), num_boost_round=300)\n",
        "bst3 = lgb.train({'num_leaves': 100, 'learning_rate': 0.1, 'num_iterations': 120}, \\\n",
        "                 lgb.Dataset(X_train_maybe[:-leave_out], label=y_train[:-leave_out]), num_boost_round=400)\n",
        "bst4 = lgb.train({'num_leaves': 100, 'learning_rate': 0.1, 'num_iterations': 130}, \\\n",
        "                 lgb.Dataset(X_train_maybe[:-leave_out], label=y_train[:-leave_out]), num_boost_round=500)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABzCMzO9wogl",
        "outputId": "0a073867-d634-4f3f-e805-dbb38e877f82"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(bst4.predict(X_train_maybe[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(bst4.predict(X_train_maybe[-leave_out:]), y_train[-leave_out:], squared=False))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125764.86667711077\n",
            "177361.96350137918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueXotyO53s3e",
        "outputId": "e3d931c5-d235-4b25-8c73-2d4cfecd7f63"
      },
      "source": [
        "bst5 = lgb.train({'num_leaves': 200, 'learning_rate': 0.05, 'num_iterations': 500}, \\\n",
        "                 lgb.Dataset(X_train_ready[:-leave_out], label=y_train[:-leave_out]), num_boost_round=500)"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GMG0VgE0Iuf",
        "outputId": "3e4d56b7-c272-4e76-bfa6-efc04f675ac6"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(bst5.predict(X_train_ready[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(bst5.predict(X_train_ready[-leave_out:]), y_train[-leave_out:], squared=False))"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65347.59679381143\n",
            "176652.16909470037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHzZkIjhUKSJ",
        "outputId": "5d793f80-9b15-4ef4-ba71-314d7d5a6b8b"
      },
      "source": [
        "# sklearn GB-reg\n",
        "sk_gbm = GradientBoostingRegressor(random_state=42, max_depth=10)\n",
        "sk_gbm.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])\n",
        "sk_gbm1 = GradientBoostingRegressor(random_state=42, max_depth=11)\n",
        "sk_gbm1.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])\n",
        "sk_gbm1 = GradientBoostingRegressor(random_state=42, max_depth=11, n_estimators=100)\n",
        "sk_gbm1.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=0.1, loss='ls', max_depth=11,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=42, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nASJ9gcuUY4q",
        "outputId": "80cc0555-7deb-41a9-89ff-229eb2f1de16"
      },
      "source": [
        "# sklearn RF-reg\n",
        "regr = RandomForestRegressor(max_depth=10, random_state=42, n_estimators=100)\n",
        "regr.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])\n",
        "regr1 = RandomForestRegressor(max_depth=10, random_state=42, n_estimators=150)\n",
        "regr1.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=150, n_jobs=None, oob_score=False,\n",
              "                      random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eNc2uAXUjIZ",
        "outputId": "b5f318c9-99f2-4e97-d611-0e8795de92b9"
      },
      "source": [
        "# sklearn LR\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b69pu8nBUvRl",
        "outputId": "5419c7cd-121f-4ce3-e732-f46862ad97e9"
      },
      "source": [
        "# sklearn ElasticNet\n",
        "enet = ElasticNet(random_state=42, max_iter=1000, alpha=.8)\n",
        "enet.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])\n",
        "enet1 = ElasticNet(random_state=42, max_iter=1000, alpha=.9, l1_ratio=.9)\n",
        "enet1.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])\n",
        "enet2 = ElasticNet(random_state=42, max_iter=1000)\n",
        "enet2.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4302156120694931.0, tolerance: 1102078172617.1133\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4784674329586068.0, tolerance: 1102078172617.1133\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3059636918434583.0, tolerance: 1102078172617.1133\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
              "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
              "           random_state=42, selection='cyclic', tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnNzMxv6UpVx",
        "outputId": "01081bf4-2845-45c5-9919-d1ca4d7e2cba"
      },
      "source": [
        "# sklearn SVR\n",
        "svr = SVR(max_iter=1000, kernel='rbf')\n",
        "svr.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])\n",
        "svr1 = SVR(max_iter=1000, kernel='poly')\n",
        "svr1.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
              "    kernel='poly', max_iter=1000, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otB3K7za0Md9",
        "outputId": "63964d80-99ae-4255-9ae9-fe9aad6b9ed1"
      },
      "source": [
        "xgb_model = xgb.XGBRegressor(random_state=42, max_depth=10, objective='reg:squarederror', learning_rate=.1)\n",
        "xgb_model.fit(X_train_maybe[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=10, min_child_weight=1, missing=None, n_estimators=100,\n",
              "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
              "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "             seed=None, silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG9rQNmuUuPS"
      },
      "source": [
        "ensemble = [xgb_model, xgb_model1, bst, bst1, bst2, bst3, bst4, sk_gbm, \\\n",
        "            regr, regr1,# regr2, regr3, \\\n",
        "            knn, knn1,\n",
        "            lr] #, enet, enet1, enet2, svr, svr1]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UClLbY17QTOI"
      },
      "source": [
        "ensemble = [xgb_model, sk_gbm, regr, lr, knn]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHWW0rEYpvOz"
      },
      "source": [
        "y_stack = []\n",
        "for m in ensemble:\n",
        "  y_stack.append(m.predict(X_train_maybe[-leave_out:-10000]))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufHlHhZj1oXK",
        "outputId": "3f303ffb-b88d-4f4d-83c3-91d7d08ef363"
      },
      "source": [
        "y_stack"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([789017.44, 933341.44, 442057.72, ..., 394445.34, 948606.06,\n",
              "        798141.2 ], dtype=float32),\n",
              " array([801385.9 , 910252.2 , 423095.88, ..., 412414.  , 900564.06,\n",
              "        805068.2 ], dtype=float32),\n",
              " array([775190.94385082, 954042.23498704, 471174.40821308, ...,\n",
              "        383837.33211987, 986435.52273157, 688721.73273023]),\n",
              " array([775190.94385082, 954042.23498704, 471174.40821308, ...,\n",
              "        383837.33211987, 986435.52273157, 688721.73273023]),\n",
              " array([773186.33271161, 951554.69402617, 466027.57610934, ...,\n",
              "        383866.72442383, 979126.4573706 , 680618.33408751]),\n",
              " array([768817.60789738, 937702.18296132, 464516.00766099, ...,\n",
              "        386605.25518921, 969442.27655215, 681353.21328279]),\n",
              " array([778133.09060971, 938513.13271812, 463048.83306617, ...,\n",
              "        384354.24669166, 970253.22630895, 666695.98064512]),\n",
              " array([818829.61574743, 923912.19106202, 440310.89899836, ...,\n",
              "        401275.37690746, 923444.97207388, 822167.11070327]),\n",
              " array([919222.38597678, 923669.79387784, 421970.45821202, ...,\n",
              "        420132.02138344, 923669.79387784, 805835.04948462]),\n",
              " array([913881.157591  , 916846.0961917 , 421315.62919146, ...,\n",
              "        420691.72101157, 916846.0961917 , 800508.7216864 ]),\n",
              " array([[704900.],\n",
              "        [649000.],\n",
              "        [477400.],\n",
              "        ...,\n",
              "        [458300.],\n",
              "        [373600.],\n",
              "        [980800.]]),\n",
              " array([[939750.],\n",
              "        [832500.],\n",
              "        [409000.],\n",
              "        ...,\n",
              "        [553750.],\n",
              "        [364000.],\n",
              "        [850000.]]),\n",
              " array([[ 828145.75163853],\n",
              "        [ 967102.78110409],\n",
              "        [ 499732.79071242],\n",
              "        ...,\n",
              "        [ 339624.37487996],\n",
              "        [1052767.17413554],\n",
              "        [ 648269.24477908]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTKdzeSRr9fp"
      },
      "source": [
        "i = -3\n",
        "y_stack[i] = y_stack[i].reshape(30000,)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YpOygMXsbmT"
      },
      "source": [
        "y_stack = np.array(y_stack)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvrQxagOsdgk",
        "outputId": "697536b8-bc42-49c9-a42f-43cd4c279a5c"
      },
      "source": [
        "y_stack = y_stack.T\n",
        "y_stack.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu54xP27stpM",
        "outputId": "57a4899b-02cb-4688-f23d-749997599597"
      },
      "source": [
        "# king_gb = GradientBoostingRegressor(random_state=42, max_depth=3, n_estimators=10)\n",
        "# king_gb.fit(y_stack, y_train[-leave_out:-5000])\n",
        "# king_lr = LinearRegression()\n",
        "# king_lr.fit(y_stack, y_train[-leave_out:-5000])\n",
        "from sklearn import linear_model\n",
        "clf = linear_model.Lasso(alpha=0.1)\n",
        "clf.fit(y_stack, y_train[-leave_out:-10000])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 466271699074935.94, tolerance: 430581887520.2816\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
              "      normalize=False, positive=False, precompute=False, random_state=None,\n",
              "      selection='cyclic', tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zLuqawPtJQA"
      },
      "source": [
        "y_stack_val = []\n",
        "for m in ensemble:\n",
        "  y_stack_val.append(m.predict(X_train_maybe[-10000:]))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPg5pZFVtY3K"
      },
      "source": [
        "i = -3\n",
        "y_stack_val[i] = y_stack_val[i].reshape(10000,)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVBDUDoBtpoD"
      },
      "source": [
        "y_stack_val = np.array(y_stack_val).T"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GU1RlbOts9I",
        "outputId": "23478224-13d2-4b6c-8544-ca3a3c2f0f19"
      },
      "source": [
        "y_stack_val.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fy0oD3hYimU",
        "outputId": "761d3d4a-1bff-4e22-9649-1079bfec639b"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(clf.predict(y_stack), y_train[-leave_out:-10000], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(clf.predict(y_stack_val), y_train[-10000:], squared=False))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "176308.7637188863\n",
            "172291.4185564711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OGrzQMR4IZT",
        "outputId": "018f7fbf-1aec-48de-d651-8f36f1e713f1"
      },
      "source": [
        "clf.coef_"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.37611982, -0.14216703,  0.26789151,  0.        ,  0.18462019,\n",
              "       -0.10945193,  0.28145413,  0.15571935, -0.09086701,  0.04828178,\n",
              "       -0.00137279,  0.00260919,  0.02074448])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKFwkqcC-hDZ"
      },
      "source": [
        "extra_X = pd.read_csv('/content/datathon21/Mo/Features_Data/Amenities_features_Train.csv')"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPMTeOSY-4xd",
        "outputId": "450b198e-7db4-465d-b262-150d8132239e"
      },
      "source": [
        "extra_X.columns"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Center_point', 'lat', 'long',\n",
              "       'Public transport in 1km radius', 'Hospital in 1km radius',\n",
              "       'Church in 1km radius', 'Kindergarten in 1km radius',\n",
              "       'BeachDensity in 1km radius', 'Km to CBD'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiIXyc_W_mD5",
        "outputId": "e8c2ee28-cabf-4b57-debb-97c14a331501"
      },
      "source": [
        "xgb_model2 = xgb.XGBRegressor(random_state=42, max_depth=10, objective='reg:squarederror', learning_rate=0.075, n_estimators=50)\n",
        "xgb_model2.fit(X[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.075, max_delta_step=0,\n",
              "             max_depth=10, min_child_weight=1, missing=None, n_estimators=50,\n",
              "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
              "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "             seed=None, silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQar9v-dB9RN",
        "outputId": "896e674a-a82e-4d40-9c6e-af506a30b20f"
      },
      "source": [
        "sk_gbm1 = GradientBoostingRegressor(random_state=42, max_depth=10, n_estimators=100)\n",
        "sk_gbm1.fit(X[:-leave_out], y_train[:-leave_out])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=0.1, loss='ls', max_depth=10,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=42, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JggVk-sAMIe",
        "outputId": "a796de86-1e68-4fa1-f57f-bbdc4cd5beb0"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(sk_gbm.predict(X_train_maybe[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklea7rn.metrics.mean_squared_error(sk_gbm.predict(X_train_maybe[-leave_out:]), y_train[-leave_out:], squared=False))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99809.31858605916\n",
            "186200.24158278774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbWRq2bGAMyq",
        "outputId": "bde511fe-3f1c-4c8a-b453-1274096fc30f"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(sk_gbm1.predict(X[:-leave_out]), y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(sk_gbm1.predict(X[-leave_out:]), y_train[-leave_out:], squared=False))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97135.85793303559\n",
            "192130.0940298709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCgWAA4qHetd"
      },
      "source": [
        "def all_models():\n",
        "  0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4UOz-HTMMt8"
      },
      "source": [
        "NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFa6XH25aZi6"
      },
      "source": [
        "def nn(input_dim, output_dim, hidden_layers = 3, nodes = 100, l2_regularization = 0.0,\n",
        "       s = 0.05, random = False, learning_rate = 0.001):\n",
        "  input_layer = Input(shape=(input_dim, ), name='Input_Layer')\n",
        "  l = Dense(nodes, activation = 'relu', \n",
        "            kernel_initializer = tf.compat.v1.keras.initializers.RandomUniform(minval=-s, maxval=s),\n",
        "            kernel_regularizer = regularizers.l2(l2_regularization),\n",
        "            bias_regularizer = regularizers.l2(l2_regularization), \n",
        "            trainable=not(random), name=f'ReLU_Layer_{0}')(input_layer)\n",
        "  for i in range(hidden_layers - 1):\n",
        "    l = Dense(nodes, activation = 'relu', \n",
        "            kernel_initializer = tf.compat.v1.keras.initializers.RandomUniform(minval=-s, maxval=s),\n",
        "            kernel_regularizer = regularizers.l2(l2_regularization),\n",
        "            bias_regularizer = regularizers.l2(l2_regularization), \n",
        "            trainable=not(random), name=f'ReLU_Layer_{i+1}')(l)\n",
        "  l = Dense(output_dim, activation='linear',\n",
        "            kernel_initializer = tf.compat.v1.keras.initializers.RandomUniform(minval=-s, maxval=s),\n",
        "            bias_initializer = tf.compat.v1.keras.initializers.RandomUniform(minval=-s, maxval=s), \n",
        "            kernel_regularizer = regularizers.l2(l2_regularization),\n",
        "            name = f\"Output_Layer\")(l)\n",
        "  model = Model(inputs=[input_layer], outputs=l)\n",
        "  loss_fct = 'MSE'\n",
        "  model.compile(optimizer = tf.keras.optimizers.Adam(lr = learning_rate),\n",
        "                loss = loss_fct, metrics = ['MSE'])\n",
        "  return model\n",
        "\n",
        "def nn_(nodes = 10):\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Dense(nodes, activation=\"relu\"))\n",
        "  model.add(layers.Dense(nodes, activation=\"relu\"))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(tf.keras.optimizers.Adam(0.01), 'MSE')\n",
        "  return model"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU1B9OaZ5Oek"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler((-1,1))\n",
        "nn_x_train = scaler.fit_transform(X_train)\n",
        "nn_y_train = scaler.fit_transform(y_train)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTJAeD156MWO",
        "outputId": "a1e7093e-9eb6-4ba4-9e38-b5d5b0b46042"
      },
      "source": [
        "nn_y_train.shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84568, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWBTe9I_dyIh",
        "outputId": "b6f74a33-30f2-4d81-f513-09beb74a9b61"
      },
      "source": [
        "nn_x_train"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6607809 , -0.06047878,  0.0217442 , ..., -0.62482861,\n",
              "        -0.94857177, -0.66334257],\n",
              "       [-0.24944044, -0.23069779, -0.09976711, ..., -0.69038302,\n",
              "        -0.96655465, -0.72079578],\n",
              "       [-0.17383735, -0.67340978,  0.50428172, ...,  0.19601269,\n",
              "        -0.8912226 ,  0.16530802],\n",
              "       ...,\n",
              "       [-0.24944044, -0.04658093,  0.1758466 , ..., -0.41935807,\n",
              "        -0.9418507 , -0.45031357],\n",
              "       [ 0.49365829, -0.03384935,  0.17267753, ..., -0.45616862,\n",
              "        -0.93478957, -0.4852216 ],\n",
              "       [-0.00969908,  0.76124877, -0.69377365, ...,  0.3890329 ,\n",
              "        -0.87886062,  0.42164698]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jahAhLS5KOX",
        "outputId": "53202ecd-99ad-466f-f553-0dc9adfc35e9"
      },
      "source": [
        "nn_x_train.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84568, 729)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ApvXccE6joE"
      },
      "source": [
        "leave_out = 50000"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZE1_mNpdCZq",
        "outputId": "8e9abfb5-4220-497d-c937-ff6c598c8023"
      },
      "source": [
        "nn_model = nn(729, 1, 5, 100, learning_rate=0.00001, l2_regularization=0.001*0)\n",
        "# nn_model = nn_(100)\n",
        "# nn_model.fit(np.asarray(X_train_maybe[:-leave_out]).astype('float32'),\n",
        "#              np.asarray(y_train[:-leave_out]).astype('float32'),\n",
        "#              batch_size=None, epochs=10)\n",
        "# nn_model.fit(np.asarray(nn_x_train[:-leave_out]).astype('float32'),\n",
        "#              np.asarray(nn_y_train[:-leave_out]).astype('float32'),\n",
        "#              batch_size=None, epochs=10)\n",
        "nn_model.fit(nn_x_train[:-leave_out],\n",
        "             nn_y_train[:-leave_out],\n",
        "             batch_size=1024, epochs=500)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.6278 - MSE: 0.6278\n",
            "Epoch 2/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.6290 - MSE: 0.6290\n",
            "Epoch 3/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.6260 - MSE: 0.6260\n",
            "Epoch 4/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.6187 - MSE: 0.6187\n",
            "Epoch 5/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.6109 - MSE: 0.6109\n",
            "Epoch 6/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.5967 - MSE: 0.5967\n",
            "Epoch 7/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.5744 - MSE: 0.5744\n",
            "Epoch 8/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.5391 - MSE: 0.5391\n",
            "Epoch 9/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.4842 - MSE: 0.4842\n",
            "Epoch 10/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.4050 - MSE: 0.4050\n",
            "Epoch 11/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.3029 - MSE: 0.3029\n",
            "Epoch 12/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.1930 - MSE: 0.1930\n",
            "Epoch 13/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.1023 - MSE: 0.1023\n",
            "Epoch 14/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0550 - MSE: 0.0550\n",
            "Epoch 15/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0426 - MSE: 0.0426\n",
            "Epoch 16/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0407 - MSE: 0.0407\n",
            "Epoch 17/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0411 - MSE: 0.0411\n",
            "Epoch 18/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0414 - MSE: 0.0414\n",
            "Epoch 19/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0403 - MSE: 0.0403\n",
            "Epoch 20/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0408 - MSE: 0.0408\n",
            "Epoch 21/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0419 - MSE: 0.0419\n",
            "Epoch 22/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0414 - MSE: 0.0414\n",
            "Epoch 23/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0417 - MSE: 0.0417\n",
            "Epoch 24/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0408 - MSE: 0.0408\n",
            "Epoch 25/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0417 - MSE: 0.0417\n",
            "Epoch 26/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0413 - MSE: 0.0413\n",
            "Epoch 27/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0407 - MSE: 0.0407\n",
            "Epoch 28/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0423 - MSE: 0.0423\n",
            "Epoch 29/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0413 - MSE: 0.0413\n",
            "Epoch 30/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0407 - MSE: 0.0407\n",
            "Epoch 31/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0416 - MSE: 0.0416\n",
            "Epoch 32/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0413 - MSE: 0.0413\n",
            "Epoch 33/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0401 - MSE: 0.0401\n",
            "Epoch 34/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0428 - MSE: 0.0428\n",
            "Epoch 35/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0405 - MSE: 0.0405\n",
            "Epoch 36/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0416 - MSE: 0.0416\n",
            "Epoch 37/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0403 - MSE: 0.0403\n",
            "Epoch 38/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0405 - MSE: 0.0405\n",
            "Epoch 39/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0416 - MSE: 0.0416\n",
            "Epoch 40/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0404 - MSE: 0.0404\n",
            "Epoch 41/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0410 - MSE: 0.0410\n",
            "Epoch 42/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0394 - MSE: 0.0394\n",
            "Epoch 43/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0431 - MSE: 0.0431\n",
            "Epoch 44/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0412 - MSE: 0.0412\n",
            "Epoch 45/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0405 - MSE: 0.0405\n",
            "Epoch 46/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0402 - MSE: 0.0402\n",
            "Epoch 47/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0406 - MSE: 0.0406\n",
            "Epoch 48/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0399 - MSE: 0.0399\n",
            "Epoch 49/500\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.0402 - MSE: 0.0402\n",
            "Epoch 50/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0410 - MSE: 0.0410\n",
            "Epoch 51/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0408 - MSE: 0.0408\n",
            "Epoch 52/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0408 - MSE: 0.0408\n",
            "Epoch 53/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0412 - MSE: 0.0412\n",
            "Epoch 54/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0396 - MSE: 0.0396\n",
            "Epoch 55/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0401 - MSE: 0.0401\n",
            "Epoch 56/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0398 - MSE: 0.0398\n",
            "Epoch 57/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0401 - MSE: 0.0401\n",
            "Epoch 58/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0396 - MSE: 0.0396\n",
            "Epoch 59/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0425 - MSE: 0.0425\n",
            "Epoch 60/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0412 - MSE: 0.0412\n",
            "Epoch 61/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0410 - MSE: 0.0410\n",
            "Epoch 62/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0395 - MSE: 0.0395\n",
            "Epoch 63/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0404 - MSE: 0.0404\n",
            "Epoch 64/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0402 - MSE: 0.0402\n",
            "Epoch 65/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0392 - MSE: 0.0392\n",
            "Epoch 66/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0396 - MSE: 0.0396\n",
            "Epoch 67/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0400 - MSE: 0.0400\n",
            "Epoch 68/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0399 - MSE: 0.0399\n",
            "Epoch 69/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0406 - MSE: 0.0406\n",
            "Epoch 70/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0409 - MSE: 0.0409\n",
            "Epoch 71/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0399 - MSE: 0.0399\n",
            "Epoch 72/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0380 - MSE: 0.0380\n",
            "Epoch 73/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0388 - MSE: 0.0388\n",
            "Epoch 74/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0402 - MSE: 0.0402\n",
            "Epoch 75/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0391 - MSE: 0.0391\n",
            "Epoch 76/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0397 - MSE: 0.0397\n",
            "Epoch 77/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0389 - MSE: 0.0389\n",
            "Epoch 78/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0380 - MSE: 0.0380\n",
            "Epoch 79/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0375 - MSE: 0.0375\n",
            "Epoch 80/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0395 - MSE: 0.0395\n",
            "Epoch 81/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0391 - MSE: 0.0391\n",
            "Epoch 82/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0400 - MSE: 0.0400\n",
            "Epoch 83/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0385 - MSE: 0.0385\n",
            "Epoch 84/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0385 - MSE: 0.0385\n",
            "Epoch 85/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0387 - MSE: 0.0387\n",
            "Epoch 86/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0390 - MSE: 0.0390\n",
            "Epoch 87/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0393 - MSE: 0.0393\n",
            "Epoch 88/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0361 - MSE: 0.0361\n",
            "Epoch 89/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0376 - MSE: 0.0376\n",
            "Epoch 90/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0389 - MSE: 0.0389\n",
            "Epoch 91/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0377 - MSE: 0.0377\n",
            "Epoch 92/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0381 - MSE: 0.0381\n",
            "Epoch 93/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0383 - MSE: 0.0383\n",
            "Epoch 94/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0388 - MSE: 0.0388\n",
            "Epoch 95/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0371 - MSE: 0.0371\n",
            "Epoch 96/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0392 - MSE: 0.0392\n",
            "Epoch 97/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0364 - MSE: 0.0364\n",
            "Epoch 98/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0380 - MSE: 0.0380\n",
            "Epoch 99/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0374 - MSE: 0.0374\n",
            "Epoch 100/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0365 - MSE: 0.0365\n",
            "Epoch 101/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0376 - MSE: 0.0376\n",
            "Epoch 102/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0348 - MSE: 0.0348\n",
            "Epoch 103/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0368 - MSE: 0.0368\n",
            "Epoch 104/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0373 - MSE: 0.0373\n",
            "Epoch 105/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0347 - MSE: 0.0347\n",
            "Epoch 106/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0374 - MSE: 0.0374\n",
            "Epoch 107/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0352 - MSE: 0.0352\n",
            "Epoch 108/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0374 - MSE: 0.0374\n",
            "Epoch 109/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0364 - MSE: 0.0364\n",
            "Epoch 110/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0356 - MSE: 0.0356\n",
            "Epoch 111/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0347 - MSE: 0.0347\n",
            "Epoch 112/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0354 - MSE: 0.0354\n",
            "Epoch 113/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0334 - MSE: 0.0334\n",
            "Epoch 114/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0338 - MSE: 0.0338\n",
            "Epoch 115/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0347 - MSE: 0.0347\n",
            "Epoch 116/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0335 - MSE: 0.0335\n",
            "Epoch 117/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0332 - MSE: 0.0332\n",
            "Epoch 118/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0337 - MSE: 0.0337\n",
            "Epoch 119/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0337 - MSE: 0.0337\n",
            "Epoch 120/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0338 - MSE: 0.0338\n",
            "Epoch 121/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0337 - MSE: 0.0337\n",
            "Epoch 122/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0326 - MSE: 0.0326\n",
            "Epoch 123/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0332 - MSE: 0.0332\n",
            "Epoch 124/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0312 - MSE: 0.0312\n",
            "Epoch 125/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0331 - MSE: 0.0331\n",
            "Epoch 126/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0321 - MSE: 0.0321\n",
            "Epoch 127/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0315 - MSE: 0.0315\n",
            "Epoch 128/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0319 - MSE: 0.0319\n",
            "Epoch 129/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0302 - MSE: 0.0302\n",
            "Epoch 130/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0308 - MSE: 0.0308\n",
            "Epoch 131/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0316 - MSE: 0.0316\n",
            "Epoch 132/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0307 - MSE: 0.0307\n",
            "Epoch 133/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0295 - MSE: 0.0295\n",
            "Epoch 134/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0275 - MSE: 0.0275\n",
            "Epoch 135/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0286 - MSE: 0.0286\n",
            "Epoch 136/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0283 - MSE: 0.0283\n",
            "Epoch 137/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0286 - MSE: 0.0286\n",
            "Epoch 138/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0285 - MSE: 0.0285\n",
            "Epoch 139/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0274 - MSE: 0.0274\n",
            "Epoch 140/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0272 - MSE: 0.0272\n",
            "Epoch 141/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0257 - MSE: 0.0257\n",
            "Epoch 142/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0256 - MSE: 0.0256\n",
            "Epoch 143/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0254 - MSE: 0.0254\n",
            "Epoch 144/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0246 - MSE: 0.0246\n",
            "Epoch 145/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0245 - MSE: 0.0245\n",
            "Epoch 146/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0241 - MSE: 0.0241\n",
            "Epoch 147/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0225 - MSE: 0.0225\n",
            "Epoch 148/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0222 - MSE: 0.0222\n",
            "Epoch 149/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0229 - MSE: 0.0229\n",
            "Epoch 150/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0237 - MSE: 0.0237\n",
            "Epoch 151/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0226 - MSE: 0.0226\n",
            "Epoch 152/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0225 - MSE: 0.0225\n",
            "Epoch 153/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0213 - MSE: 0.0213\n",
            "Epoch 154/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0223 - MSE: 0.0223\n",
            "Epoch 155/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0227 - MSE: 0.0227\n",
            "Epoch 156/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0201 - MSE: 0.0201\n",
            "Epoch 157/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0219 - MSE: 0.0219\n",
            "Epoch 158/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0214 - MSE: 0.0214\n",
            "Epoch 159/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0202 - MSE: 0.0202\n",
            "Epoch 160/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0204 - MSE: 0.0204\n",
            "Epoch 161/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0206 - MSE: 0.0206\n",
            "Epoch 162/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0185 - MSE: 0.0185\n",
            "Epoch 163/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0199 - MSE: 0.0199\n",
            "Epoch 164/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0201 - MSE: 0.0201\n",
            "Epoch 165/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0205 - MSE: 0.0205\n",
            "Epoch 166/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0200 - MSE: 0.0200\n",
            "Epoch 167/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0185 - MSE: 0.0185\n",
            "Epoch 168/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0198 - MSE: 0.0198\n",
            "Epoch 169/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0187 - MSE: 0.0187\n",
            "Epoch 170/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0193 - MSE: 0.0193\n",
            "Epoch 171/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0184 - MSE: 0.0184\n",
            "Epoch 172/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0189 - MSE: 0.0189\n",
            "Epoch 173/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0191 - MSE: 0.0191\n",
            "Epoch 174/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0180 - MSE: 0.0180\n",
            "Epoch 175/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0186 - MSE: 0.0186\n",
            "Epoch 176/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0186 - MSE: 0.0186\n",
            "Epoch 177/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0185 - MSE: 0.0185\n",
            "Epoch 178/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0182 - MSE: 0.0182\n",
            "Epoch 179/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0181 - MSE: 0.0181\n",
            "Epoch 180/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0183 - MSE: 0.0183\n",
            "Epoch 181/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0179 - MSE: 0.0179\n",
            "Epoch 182/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0184 - MSE: 0.0184\n",
            "Epoch 183/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0185 - MSE: 0.0185\n",
            "Epoch 184/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0177 - MSE: 0.0177\n",
            "Epoch 185/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0178 - MSE: 0.0178\n",
            "Epoch 186/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0173 - MSE: 0.0173\n",
            "Epoch 187/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0172 - MSE: 0.0172\n",
            "Epoch 188/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0173 - MSE: 0.0173\n",
            "Epoch 189/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0170 - MSE: 0.0170\n",
            "Epoch 190/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0174 - MSE: 0.0174\n",
            "Epoch 191/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0178 - MSE: 0.0178\n",
            "Epoch 192/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0169 - MSE: 0.0169\n",
            "Epoch 193/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0171 - MSE: 0.0171\n",
            "Epoch 194/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0173 - MSE: 0.0173\n",
            "Epoch 195/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0174 - MSE: 0.0174\n",
            "Epoch 196/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0171 - MSE: 0.0171\n",
            "Epoch 197/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0181 - MSE: 0.0181\n",
            "Epoch 198/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0173 - MSE: 0.0173\n",
            "Epoch 199/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0166 - MSE: 0.0166\n",
            "Epoch 200/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0169 - MSE: 0.0169\n",
            "Epoch 201/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0176 - MSE: 0.0176\n",
            "Epoch 202/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0162 - MSE: 0.0162\n",
            "Epoch 203/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0173 - MSE: 0.0173\n",
            "Epoch 204/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0174 - MSE: 0.0174\n",
            "Epoch 205/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0171 - MSE: 0.0171\n",
            "Epoch 206/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0171 - MSE: 0.0171\n",
            "Epoch 207/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0168 - MSE: 0.0168\n",
            "Epoch 208/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0171 - MSE: 0.0171\n",
            "Epoch 209/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0166 - MSE: 0.0166\n",
            "Epoch 210/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0169 - MSE: 0.0169\n",
            "Epoch 211/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0161 - MSE: 0.0161\n",
            "Epoch 212/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0165 - MSE: 0.0165\n",
            "Epoch 213/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0170 - MSE: 0.0170\n",
            "Epoch 214/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0161 - MSE: 0.0161\n",
            "Epoch 215/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0159 - MSE: 0.0159\n",
            "Epoch 216/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0164 - MSE: 0.0164\n",
            "Epoch 217/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0161 - MSE: 0.0161\n",
            "Epoch 218/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0163 - MSE: 0.0163\n",
            "Epoch 219/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0162 - MSE: 0.0162\n",
            "Epoch 220/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0164 - MSE: 0.0164\n",
            "Epoch 221/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0159 - MSE: 0.0159\n",
            "Epoch 222/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0160 - MSE: 0.0160\n",
            "Epoch 223/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0166 - MSE: 0.0166\n",
            "Epoch 224/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0166 - MSE: 0.0166\n",
            "Epoch 225/500\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0163 - MSE: 0.0163\n",
            "Epoch 226/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0159 - MSE: 0.0159\n",
            "Epoch 227/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0158 - MSE: 0.0158\n",
            "Epoch 228/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0154 - MSE: 0.0154\n",
            "Epoch 229/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0155 - MSE: 0.0155\n",
            "Epoch 230/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0154 - MSE: 0.0154\n",
            "Epoch 231/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0161 - MSE: 0.0161\n",
            "Epoch 232/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0157 - MSE: 0.0157\n",
            "Epoch 233/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0150 - MSE: 0.0150\n",
            "Epoch 234/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0159 - MSE: 0.0159\n",
            "Epoch 235/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0156 - MSE: 0.0156\n",
            "Epoch 236/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0156 - MSE: 0.0156\n",
            "Epoch 237/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0155 - MSE: 0.0155\n",
            "Epoch 238/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0156 - MSE: 0.0156\n",
            "Epoch 239/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0150 - MSE: 0.0150\n",
            "Epoch 240/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0157 - MSE: 0.0157\n",
            "Epoch 241/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0154 - MSE: 0.0154\n",
            "Epoch 242/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0155 - MSE: 0.0155\n",
            "Epoch 243/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0149 - MSE: 0.0149\n",
            "Epoch 244/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0155 - MSE: 0.0155\n",
            "Epoch 245/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0157 - MSE: 0.0157\n",
            "Epoch 246/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0151 - MSE: 0.0151\n",
            "Epoch 247/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0146 - MSE: 0.0146\n",
            "Epoch 248/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0150 - MSE: 0.0150\n",
            "Epoch 249/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0147 - MSE: 0.0147\n",
            "Epoch 250/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0156 - MSE: 0.0156\n",
            "Epoch 251/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0147 - MSE: 0.0147\n",
            "Epoch 252/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0149 - MSE: 0.0149\n",
            "Epoch 253/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0149 - MSE: 0.0149\n",
            "Epoch 254/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0148 - MSE: 0.0148\n",
            "Epoch 255/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0144 - MSE: 0.0144\n",
            "Epoch 256/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0146 - MSE: 0.0146\n",
            "Epoch 257/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0148 - MSE: 0.0148\n",
            "Epoch 258/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0155 - MSE: 0.0155\n",
            "Epoch 259/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0153 - MSE: 0.0153\n",
            "Epoch 260/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0151 - MSE: 0.0151\n",
            "Epoch 261/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0152 - MSE: 0.0152\n",
            "Epoch 262/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0150 - MSE: 0.0150\n",
            "Epoch 263/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0143 - MSE: 0.0143\n",
            "Epoch 264/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0150 - MSE: 0.0150\n",
            "Epoch 265/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0153 - MSE: 0.0153\n",
            "Epoch 266/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0146 - MSE: 0.0146\n",
            "Epoch 267/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0150 - MSE: 0.0150\n",
            "Epoch 268/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0143 - MSE: 0.0143\n",
            "Epoch 269/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0146 - MSE: 0.0146\n",
            "Epoch 270/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0145 - MSE: 0.0145\n",
            "Epoch 271/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0145 - MSE: 0.0145\n",
            "Epoch 272/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0148 - MSE: 0.0148\n",
            "Epoch 273/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0140 - MSE: 0.0140\n",
            "Epoch 274/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0143 - MSE: 0.0143\n",
            "Epoch 275/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0146 - MSE: 0.0146\n",
            "Epoch 276/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0146 - MSE: 0.0146\n",
            "Epoch 277/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0141 - MSE: 0.0141\n",
            "Epoch 278/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0143 - MSE: 0.0143\n",
            "Epoch 279/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0146 - MSE: 0.0146\n",
            "Epoch 280/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0138 - MSE: 0.0138\n",
            "Epoch 281/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0143 - MSE: 0.0143\n",
            "Epoch 282/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0145 - MSE: 0.0145\n",
            "Epoch 283/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0147 - MSE: 0.0147\n",
            "Epoch 284/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0147 - MSE: 0.0147\n",
            "Epoch 285/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0148 - MSE: 0.0148\n",
            "Epoch 286/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0145 - MSE: 0.0145\n",
            "Epoch 287/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0148 - MSE: 0.0148\n",
            "Epoch 288/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0143 - MSE: 0.0143\n",
            "Epoch 289/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0142 - MSE: 0.0142\n",
            "Epoch 290/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0138 - MSE: 0.0138\n",
            "Epoch 291/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0143 - MSE: 0.0143\n",
            "Epoch 292/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0140 - MSE: 0.0140\n",
            "Epoch 293/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0139 - MSE: 0.0139\n",
            "Epoch 294/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0144 - MSE: 0.0144\n",
            "Epoch 295/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0140 - MSE: 0.0140\n",
            "Epoch 296/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0138 - MSE: 0.0138\n",
            "Epoch 297/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0148 - MSE: 0.0148\n",
            "Epoch 298/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0138 - MSE: 0.0138\n",
            "Epoch 299/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0145 - MSE: 0.0145\n",
            "Epoch 300/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0147 - MSE: 0.0147\n",
            "Epoch 301/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0139 - MSE: 0.0139\n",
            "Epoch 302/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0143 - MSE: 0.0143\n",
            "Epoch 303/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0138 - MSE: 0.0138\n",
            "Epoch 304/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0136 - MSE: 0.0136\n",
            "Epoch 305/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0134 - MSE: 0.0134\n",
            "Epoch 306/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0138 - MSE: 0.0138\n",
            "Epoch 307/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0135 - MSE: 0.0135\n",
            "Epoch 308/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0145 - MSE: 0.0145\n",
            "Epoch 309/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0138 - MSE: 0.0138\n",
            "Epoch 310/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0142 - MSE: 0.0142\n",
            "Epoch 311/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0140 - MSE: 0.0140\n",
            "Epoch 312/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0141 - MSE: 0.0141\n",
            "Epoch 313/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0144 - MSE: 0.0144\n",
            "Epoch 314/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0141 - MSE: 0.0141\n",
            "Epoch 315/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0141 - MSE: 0.0141\n",
            "Epoch 316/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0139 - MSE: 0.0139\n",
            "Epoch 317/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0139 - MSE: 0.0139\n",
            "Epoch 318/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0137 - MSE: 0.0137\n",
            "Epoch 319/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0137 - MSE: 0.0137\n",
            "Epoch 320/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0140 - MSE: 0.0140\n",
            "Epoch 321/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0143 - MSE: 0.0143\n",
            "Epoch 322/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0140 - MSE: 0.0140\n",
            "Epoch 323/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0135 - MSE: 0.0135\n",
            "Epoch 324/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0142 - MSE: 0.0142\n",
            "Epoch 325/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0141 - MSE: 0.0141\n",
            "Epoch 326/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0134 - MSE: 0.0134\n",
            "Epoch 327/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0142 - MSE: 0.0142\n",
            "Epoch 328/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0140 - MSE: 0.0140\n",
            "Epoch 329/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0139 - MSE: 0.0139\n",
            "Epoch 330/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0135 - MSE: 0.0135\n",
            "Epoch 331/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0143 - MSE: 0.0143\n",
            "Epoch 332/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0136 - MSE: 0.0136\n",
            "Epoch 333/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0135 - MSE: 0.0135\n",
            "Epoch 334/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0137 - MSE: 0.0137\n",
            "Epoch 335/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0135 - MSE: 0.0135\n",
            "Epoch 336/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0142 - MSE: 0.0142\n",
            "Epoch 337/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0136 - MSE: 0.0136\n",
            "Epoch 338/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0133 - MSE: 0.0133\n",
            "Epoch 339/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0133 - MSE: 0.0133\n",
            "Epoch 340/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0135 - MSE: 0.0135\n",
            "Epoch 341/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0132 - MSE: 0.0132\n",
            "Epoch 342/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0133 - MSE: 0.0133\n",
            "Epoch 343/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0138 - MSE: 0.0138\n",
            "Epoch 344/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0136 - MSE: 0.0136\n",
            "Epoch 345/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0140 - MSE: 0.0140\n",
            "Epoch 346/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0137 - MSE: 0.0137\n",
            "Epoch 347/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0129 - MSE: 0.0129\n",
            "Epoch 348/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 349/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0132 - MSE: 0.0132\n",
            "Epoch 350/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0141 - MSE: 0.0141\n",
            "Epoch 351/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0132 - MSE: 0.0132\n",
            "Epoch 352/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0138 - MSE: 0.0138\n",
            "Epoch 353/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 354/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 355/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0137 - MSE: 0.0137\n",
            "Epoch 356/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 357/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 358/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 359/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0136 - MSE: 0.0136\n",
            "Epoch 360/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0134 - MSE: 0.0134\n",
            "Epoch 361/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0132 - MSE: 0.0132\n",
            "Epoch 362/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0128 - MSE: 0.0128\n",
            "Epoch 363/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0128 - MSE: 0.0128\n",
            "Epoch 364/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0132 - MSE: 0.0132\n",
            "Epoch 365/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0134 - MSE: 0.0134\n",
            "Epoch 366/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0132 - MSE: 0.0132\n",
            "Epoch 367/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0136 - MSE: 0.0136\n",
            "Epoch 368/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0134 - MSE: 0.0134\n",
            "Epoch 369/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0133 - MSE: 0.0133\n",
            "Epoch 370/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0136 - MSE: 0.0136\n",
            "Epoch 371/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0132 - MSE: 0.0132\n",
            "Epoch 372/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0133 - MSE: 0.0133\n",
            "Epoch 373/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 374/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 375/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 376/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0139 - MSE: 0.0139\n",
            "Epoch 377/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0133 - MSE: 0.0133\n",
            "Epoch 378/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0134 - MSE: 0.0134\n",
            "Epoch 379/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0133 - MSE: 0.0133\n",
            "Epoch 380/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 381/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 382/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0133 - MSE: 0.0133\n",
            "Epoch 383/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 384/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 385/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0135 - MSE: 0.0135\n",
            "Epoch 386/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0129 - MSE: 0.0129\n",
            "Epoch 387/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 388/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 389/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0136 - MSE: 0.0136\n",
            "Epoch 390/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 391/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0135 - MSE: 0.0135\n",
            "Epoch 392/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 393/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 394/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0129 - MSE: 0.0129\n",
            "Epoch 395/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0125 - MSE: 0.0125\n",
            "Epoch 396/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0121 - MSE: 0.0121\n",
            "Epoch 397/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0135 - MSE: 0.0135\n",
            "Epoch 398/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0129 - MSE: 0.0129\n",
            "Epoch 399/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 400/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0133 - MSE: 0.0133\n",
            "Epoch 401/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0132 - MSE: 0.0132\n",
            "Epoch 402/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 403/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 404/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0125 - MSE: 0.0125\n",
            "Epoch 405/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0128 - MSE: 0.0128\n",
            "Epoch 406/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 407/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0134 - MSE: 0.0134\n",
            "Epoch 408/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 409/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 410/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 411/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0134 - MSE: 0.0134\n",
            "Epoch 412/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 413/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0134 - MSE: 0.0134\n",
            "Epoch 414/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 415/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0122 - MSE: 0.0122\n",
            "Epoch 416/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0136 - MSE: 0.0136\n",
            "Epoch 417/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0123 - MSE: 0.0123\n",
            "Epoch 418/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0132 - MSE: 0.0132\n",
            "Epoch 419/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0124 - MSE: 0.0124\n",
            "Epoch 420/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0125 - MSE: 0.0125\n",
            "Epoch 421/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0121 - MSE: 0.0121\n",
            "Epoch 422/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0132 - MSE: 0.0132\n",
            "Epoch 423/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0129 - MSE: 0.0129\n",
            "Epoch 424/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0128 - MSE: 0.0128\n",
            "Epoch 425/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0128 - MSE: 0.0128\n",
            "Epoch 426/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 427/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 428/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 429/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0129 - MSE: 0.0129\n",
            "Epoch 430/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0134 - MSE: 0.0134\n",
            "Epoch 431/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 432/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0128 - MSE: 0.0128\n",
            "Epoch 433/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0125 - MSE: 0.0125\n",
            "Epoch 434/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0129 - MSE: 0.0129\n",
            "Epoch 435/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 436/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0129 - MSE: 0.0129\n",
            "Epoch 437/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0129 - MSE: 0.0129\n",
            "Epoch 438/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0125 - MSE: 0.0125\n",
            "Epoch 439/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0125 - MSE: 0.0125\n",
            "Epoch 440/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0123 - MSE: 0.0123\n",
            "Epoch 441/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0133 - MSE: 0.0133\n",
            "Epoch 442/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0125 - MSE: 0.0125\n",
            "Epoch 443/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 444/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 445/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0131 - MSE: 0.0131\n",
            "Epoch 446/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 447/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 448/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0124 - MSE: 0.0124\n",
            "Epoch 449/500\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0124 - MSE: 0.0124\n",
            "Epoch 450/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 451/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0125 - MSE: 0.0125\n",
            "Epoch 452/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0123 - MSE: 0.0123\n",
            "Epoch 453/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 454/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0124 - MSE: 0.0124\n",
            "Epoch 455/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0121 - MSE: 0.0121\n",
            "Epoch 456/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0128 - MSE: 0.0128\n",
            "Epoch 457/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0123 - MSE: 0.0123\n",
            "Epoch 458/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0119 - MSE: 0.0119\n",
            "Epoch 459/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0129 - MSE: 0.0129\n",
            "Epoch 460/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0125 - MSE: 0.0125\n",
            "Epoch 461/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0122 - MSE: 0.0122\n",
            "Epoch 462/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 463/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0124 - MSE: 0.0124\n",
            "Epoch 464/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 465/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0122 - MSE: 0.0122\n",
            "Epoch 466/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 467/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0122 - MSE: 0.0122\n",
            "Epoch 468/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0122 - MSE: 0.0122\n",
            "Epoch 469/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0125 - MSE: 0.0125\n",
            "Epoch 470/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 471/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0134 - MSE: 0.0134\n",
            "Epoch 472/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 473/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0122 - MSE: 0.0122\n",
            "Epoch 474/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0123 - MSE: 0.0123\n",
            "Epoch 475/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0128 - MSE: 0.0128\n",
            "Epoch 476/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0123 - MSE: 0.0123\n",
            "Epoch 477/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 478/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 479/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 480/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0121 - MSE: 0.0121\n",
            "Epoch 481/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0123 - MSE: 0.0123\n",
            "Epoch 482/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 483/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 484/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 485/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 486/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0123 - MSE: 0.0123\n",
            "Epoch 487/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 488/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0117 - MSE: 0.0117\n",
            "Epoch 489/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0122 - MSE: 0.0122\n",
            "Epoch 490/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0127 - MSE: 0.0127\n",
            "Epoch 491/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0121 - MSE: 0.0121\n",
            "Epoch 492/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0124 - MSE: 0.0124\n",
            "Epoch 493/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0122 - MSE: 0.0122\n",
            "Epoch 494/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0122 - MSE: 0.0122\n",
            "Epoch 495/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0123 - MSE: 0.0123\n",
            "Epoch 496/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0124 - MSE: 0.0124\n",
            "Epoch 497/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0117 - MSE: 0.0117\n",
            "Epoch 498/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0115 - MSE: 0.0115\n",
            "Epoch 499/500\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.0126 - MSE: 0.0126\n",
            "Epoch 500/500\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.0123 - MSE: 0.0123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2c615b4450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXA_4uHC7HqV"
      },
      "source": [
        "temp1 = scaler.inverse_transform(nn_model.predict(nn_x_train[:-leave_out]))\n",
        "temp2 = scaler.inverse_transform(nn_model.predict(nn_x_train[-leave_out:]))"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjxMWVF0N46g",
        "outputId": "21187179-0e6b-4b0c-c7de-17decb7e33bc"
      },
      "source": [
        "temp2 = scaler.inverse_transform(nn_model.predict(nn_x_train[-leave_out:]))\n",
        "print(sklearn.metrics.mean_squared_error(temp1,\n",
        "                                         y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(temp2,\n",
        "                                         y_train[-leave_out:], squared=False))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "213833.21506010715\n",
            "215337.71227496586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hza42UgJX74c"
      },
      "source": [
        "NN bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2nT89MeCbWk"
      },
      "source": [
        "nn_ensemble = []\n",
        "for _ in range(10):\n",
        "  temp = nn(714, 1, 2, 200, learning_rate=0.0005, l2_regularization=0.001*0)\n",
        "  temp.fit(nn_x_train[:-leave_out],\n",
        "              nn_y_train[:-leave_out],\n",
        "              batch_size=64, epochs=10, verbose=0)\n",
        "  nn_ensemble.append(temp)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDPG1FmldeGS"
      },
      "source": [
        "for _ in range(40):\n",
        "  temp = nn(23, 1, 2, 200, learning_rate=0.0005, l2_regularization=0.001*0)\n",
        "  temp.fit(nn_x_train[:-leave_out],\n",
        "              nn_y_train[:-leave_out],\n",
        "              batch_size=64, epochs=50, verbose=0)\n",
        "  nn_ensemble.append(temp)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlENZdm0XqeU"
      },
      "source": [
        "# nn_ensemble1 = []  ## with l2\n",
        "# for _ in range(10):\n",
        "#   temp = nn(23, 1, 2, 200, learning_rate=0.0005, l2_regularization=0.005)\n",
        "#   temp.fit(nn_x_train[:-leave_out],\n",
        "#               nn_y_train[:-leave_out],\n",
        "#               batch_size=64, epochs=50, verbose=0)\n",
        "#   nn_ensemble1.append(temp)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcWgl3uSartI"
      },
      "source": [
        "nn_ensemble1 = []  ## with l2\n",
        "for _ in range(10):\n",
        "  temp = nn(23, 1, 3, 100, learning_rate=0.0005, l2_regularization=0.005*0)\n",
        "  temp.fit(nn_x_train[:-leave_out],\n",
        "              nn_y_train[:-leave_out],\n",
        "              batch_size=64, epochs=30, verbose=0)\n",
        "  nn_ensemble1.append(temp)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_rGuIgUciGz"
      },
      "source": [
        "nn_ensemble2 = []  ## with l2\n",
        "for _ in range(10):\n",
        "  temp = nn(23, 1, 1, 100, learning_rate=0.0005, l2_regularization=0.005*0)\n",
        "  temp.fit(nn_x_train[:-leave_out],\n",
        "              nn_y_train[:-leave_out],\n",
        "              batch_size=64, epochs=30, verbose=0)\n",
        "  nn_ensemble2.append(temp)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6UJETDPghcA"
      },
      "source": [
        "pred = np.zeros((44568,1))\n",
        "pred_val = np.zeros((leave_out,1))\n",
        "for n in nn_ensemble:\n",
        "  pred += scaler.inverse_transform(n.predict(nn_x_train[:-leave_out]))\n",
        "  pred_val += scaler.inverse_transform(n.predict(nn_x_train[-leave_out:]))\n",
        "pred /= 10\n",
        "pred_val /= 10"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6LzcoXHlGr7"
      },
      "source": [
        "pred *= 10\n",
        "pred_val *= 10\n",
        "pred /= 50\n",
        "pred_val /= 50"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTqlLI8VYIvR"
      },
      "source": [
        "pred1 = np.zeros((34568,1))\n",
        "pred_val1 = np.zeros((leave_out,1))\n",
        "for n in nn_ensemble1:\n",
        "  pred1 += scaler.inverse_transform(n.predict(nn_x_train[:-leave_out]))\n",
        "  pred_val1 += scaler.inverse_transform(n.predict(nn_x_train[-leave_out:]))\n",
        "pred1 /= 10\n",
        "pred_val1 /= 10"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0aMWEaCcn0_"
      },
      "source": [
        "pred2 = np.zeros((34568,1))\n",
        "pred_val2 = np.zeros((leave_out,1))\n",
        "for n in nn_ensemble2:\n",
        "  pred2 += scaler.inverse_transform(n.predict(nn_x_train[:-leave_out]))\n",
        "  pred_val2 += scaler.inverse_transform(n.predict(nn_x_train[-leave_out:]))\n",
        "pred2 /= 10\n",
        "pred_val2 /= 10"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz0MfpalcNlV"
      },
      "source": [
        "pred3 = (pred + pred1 + pred2) / 3\n",
        "pred_val3 = (pred_val + pred_val1 + pred_val2) / 3"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9oTbV0DfFlB",
        "outputId": "f62823b9-76a6-4159-cd4d-9c5bb2e492fd"
      },
      "source": [
        "print(sklearn.metrics.mean_squared_error(pred,\n",
        "                                         y_train[:-leave_out], squared=False))\n",
        "print(sklearn.metrics.mean_squared_error(pred_val,\n",
        "                                         y_train[-leave_out:], squared=False))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "220543.0371615809\n",
            "222174.52905634907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhJJQtMgWrce",
        "outputId": "29eec874-8120-41a3-c693-2927364f8357"
      },
      "source": [
        "for i,_ in enumerate(nn_ensemble):\n",
        "  print(sklearn.metrics.mean_squared_error(scaler.inverse_transform(nn_ensemble[i].predict(nn_x_train[:-leave_out])),\n",
        "                                          y_train[:-leave_out], squared=False) < 165000)\n",
        "  print(sklearn.metrics.mean_squared_error(scaler.inverse_transform(nn_ensemble[i].predict(nn_x_train[-leave_out:])),\n",
        "                                          y_train[-leave_out:], squared=False) < 205000)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_ZpxwontLbo",
        "outputId": "21411315-43a3-4d35-87f8-2843322d1709"
      },
      "source": [
        "!cd datathon21/ && git pull"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/21)\u001b[K\rremote: Counting objects:   9% (2/21)\u001b[K\rremote: Counting objects:  14% (3/21)\u001b[K\rremote: Counting objects:  19% (4/21)\u001b[K\rremote: Counting objects:  23% (5/21)\u001b[K\rremote: Counting objects:  28% (6/21)\u001b[K\rremote: Counting objects:  33% (7/21)\u001b[K\rremote: Counting objects:  38% (8/21)\u001b[K\rremote: Counting objects:  42% (9/21)\u001b[K\rremote: Counting objects:  47% (10/21)\u001b[K\rremote: Counting objects:  52% (11/21)\u001b[K\rremote: Counting objects:  57% (12/21)\u001b[K\rremote: Counting objects:  61% (13/21)\u001b[K\rremote: Counting objects:  66% (14/21)\u001b[K\rremote: Counting objects:  71% (15/21)\u001b[K\rremote: Counting objects:  76% (16/21)\u001b[K\rremote: Counting objects:  80% (17/21)\u001b[K\rremote: Counting objects:  85% (18/21)\u001b[K\rremote: Counting objects:  90% (19/21)\u001b[K\rremote: Counting objects:  95% (20/21)\u001b[K\rremote: Counting objects: 100% (21/21)\u001b[K\rremote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 16 (delta 5), reused 15 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n",
            "From https://github.com/ixil/datathon21\n",
            "   9f196e4..3309823  main       -> origin/main\n",
            "Updating 9f196e4..3309823\n",
            "Fast-forward\n",
            " kei/real_estate/Output XGB prediction.ipynb       |   103 \u001b[32m+\u001b[m\n",
            " kei/real_estate/X_test.csv                        | 41654 \u001b[32m++++++++++\u001b[m\n",
            " kei/real_estate/X_train.csv                       | 84569 \u001b[32m++++++++++++++++++++\u001b[m\n",
            " kei/real_estate/latitude londitude features.ipynb |   292 \u001b[32m+\u001b[m\n",
            " kei/real_estate/preprocess_data.py                |    15 \u001b[32m+\u001b[m\n",
            " kei/real_estate/y_train.csv                       | 84569 \u001b[32m++++++++++++++++++++\u001b[m\n",
            " 6 files changed, 211202 insertions(+)\n",
            " create mode 100644 kei/real_estate/Output XGB prediction.ipynb\n",
            " create mode 100644 kei/real_estate/X_test.csv\n",
            " create mode 100644 kei/real_estate/X_train.csv\n",
            " create mode 100644 kei/real_estate/latitude londitude features.ipynb\n",
            " create mode 100644 kei/real_estate/y_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq0yoP3zsxfh",
        "outputId": "30583c86-0378-44e2-b934-d7fda42866e6"
      },
      "source": [
        "!pip install --upgrade pandas"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.7/dist-packages (1.2.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}